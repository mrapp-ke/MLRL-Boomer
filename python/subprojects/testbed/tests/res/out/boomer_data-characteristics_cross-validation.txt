INFO Configuration: Namespace(log_level=10, random_state=1, data_dir='data', dataset='emotions', folds=10, current_fold=-1, print_evaluation=False, store_evaluation=False, evaluate_training_data=False, print_prediction_characteristics=False, store_prediction_characteristics=False, print_data_characteristics=True, store_data_characteristics=True, one_hot_encoding=False, model_dir=None, parameter_dir=None, output_dir='python/subprojects/testbed/tests/res/tmp/results', print_predictions=False, store_predictions=False, predict_probabilities=False, print_model_characteristics=False, store_model_characteristics=False, print_rules=False, store_rules=False, print_options=None, feature_format='auto', label_format='auto', predicted_label_format='auto', max_rules=None, time_limit=None, label_sampling=None, instance_sampling=None, feature_sampling=None, holdout=None, pruning=None, rule_model_assemblage=None, post_optimization=None, rule_induction=None, parallel_prediction=None, statistic_format=None, default_rule=None, early_stopping=None, feature_binning=None, label_binning=None, shrinkage=None, loss=None, classification_predictor=None, probability_predictor=None, l1_regularization_weight=None, l2_regularization_weight=None, head_type=None, parallel_rule_refinement=None, parallel_statistic_update=None)
INFO Starting experiment...
INFO Performing full 10-fold cross validation...
DEBUG Parsing meta data from file "python/subprojects/testbed/tests/res/data/emotions.xml"...
DEBUG Loading data set from file "python/subprojects/testbed/tests/res/data/emotions.arff"...
INFO Fold 1 / 10:
INFO Data characteristics for experiment "boomer" (Fold 1):

Examples: 533
Features: 72 (72 numerical, 0 nominal)
Feature density: 0.9966906399833229
Feature sparsity: 0.003309360016677143
Labels: 6
Label density: 0.30988117573483426
Label sparsity: 0.6901188242651657
Label imbalance ratio: 1.4847239997553696
Label cardinality: 1.8592870544090057
Distinct label vectors: 26

INFO Fitting model to 533 training examples...
DEBUG A dense matrix is used to store the feature values of the training examples
DEBUG A dense matrix is used to store the labels of the training examples
INFO Successfully fit model in 0.30718400299974746 seconds
INFO Fold 2 / 10:
INFO Data characteristics for experiment "boomer" (Fold 2):

Examples: 533
Features: 72 (72 numerical, 0 nominal)
Feature density: 0.9966906399833229
Feature sparsity: 0.003309360016677143
Labels: 6
Label density: 0.3089430894308943
Label sparsity: 0.6910569105691057
Label imbalance ratio: 1.4496162500320688
Label cardinality: 1.853658536585366
Distinct label vectors: 26

INFO Fitting model to 533 training examples...
DEBUG A dense matrix is used to store the feature values of the training examples
DEBUG A dense matrix is used to store the labels of the training examples
INFO Successfully fit model in 0.31220350600005986 seconds
INFO Fold 3 / 10:
INFO Data characteristics for experiment "boomer" (Fold 3):

Examples: 533
Features: 72 (72 numerical, 0 nominal)
Feature density: 0.9968469877006463
Feature sparsity: 0.003153012299353719
Labels: 6
Label density: 0.31081926203877425
Label sparsity: 0.6891807379612258
Label imbalance ratio: 1.479817365111483
Label cardinality: 1.8649155722326454
Distinct label vectors: 26

INFO Fitting model to 533 training examples...
DEBUG A dense matrix is used to store the feature values of the training examples
DEBUG A dense matrix is used to store the labels of the training examples
INFO Successfully fit model in 0.33635157100025026 seconds
INFO Fold 4 / 10:
INFO Data characteristics for experiment "boomer" (Fold 4):

Examples: 534
Features: 72 (72 numerical, 0 nominal)
Feature density: 0.9967488555971702
Feature sparsity: 0.0032511444028298087
Labels: 6
Label density: 0.3139825218476904
Label sparsity: 0.6860174781523096
Label imbalance ratio: 1.4869103571697266
Label cardinality: 1.8838951310861423
Distinct label vectors: 27

INFO Fitting model to 534 training examples...
DEBUG A dense matrix is used to store the feature values of the training examples
DEBUG A dense matrix is used to store the labels of the training examples
INFO Successfully fit model in 0.3197314929998356 seconds
INFO Fold 5 / 10:
INFO Data characteristics for experiment "boomer" (Fold 5):

Examples: 534
Features: 72 (72 numerical, 0 nominal)
Feature density: 0.9966708281315023
Feature sparsity: 0.0033291718684976823
Labels: 6
Label density: 0.3099250936329588
Label sparsity: 0.6900749063670413
Label imbalance ratio: 1.4957836292208448
Label cardinality: 1.8595505617977528
Distinct label vectors: 27

INFO Fitting model to 534 training examples...
DEBUG A dense matrix is used to store the feature values of the training examples
DEBUG A dense matrix is used to store the labels of the training examples
INFO Successfully fit model in 0.3171117380002215 seconds
INFO Fold 6 / 10:
INFO Data characteristics for experiment "boomer" (Fold 6):

Examples: 534
Features: 72 (72 numerical, 0 nominal)
Feature density: 0.9967748647523929
Feature sparsity: 0.003225135247607147
Labels: 6
Label density: 0.31335830212234705
Label sparsity: 0.686641697877653
Label imbalance ratio: 1.4965924868379374
Label cardinality: 1.8801498127340823
Distinct label vectors: 27

INFO Fitting model to 534 training examples...
DEBUG A dense matrix is used to store the feature values of the training examples
DEBUG A dense matrix is used to store the labels of the training examples
INFO Successfully fit model in 0.33258301100022436 seconds
INFO Fold 7 / 10:
INFO Data characteristics for experiment "boomer" (Fold 7):

Examples: 534
Features: 72 (72 numerical, 0 nominal)
Feature density: 0.996618809821057
Feature sparsity: 0.0033811901789430054
Labels: 6
Label density: 0.31273408239700373
Label sparsity: 0.6872659176029963
Label imbalance ratio: 1.4505275727332885
Label cardinality: 1.8764044943820224
Distinct label vectors: 27

INFO Fitting model to 534 training examples...
DEBUG A dense matrix is used to store the feature values of the training examples
DEBUG A dense matrix is used to store the labels of the training examples
INFO Successfully fit model in 0.31216166799958955 seconds
INFO Fold 8 / 10:
INFO Data characteristics for experiment "boomer" (Fold 8):

Examples: 534
Features: 72 (72 numerical, 0 nominal)
Feature density: 0.9966708281315023
Feature sparsity: 0.0033291718684976823
Labels: 6
Label density: 0.31242197253433207
Label sparsity: 0.687578027465668
Label imbalance ratio: 1.4974245146160292
Label cardinality: 1.8745318352059925
Distinct label vectors: 27

INFO Fitting model to 534 training examples...
DEBUG A dense matrix is used to store the feature values of the training examples
DEBUG A dense matrix is used to store the labels of the training examples
INFO Successfully fit model in 0.3209959619998699 seconds
INFO Fold 9 / 10:
INFO Data characteristics for experiment "boomer" (Fold 9):

Examples: 534
Features: 72 (72 numerical, 0 nominal)
Feature density: 0.9967488555971702
Feature sparsity: 0.0032511444028298087
Labels: 6
Label density: 0.3105493133583021
Label sparsity: 0.6894506866416978
Label imbalance ratio: 1.4533830396850134
Label cardinality: 1.8632958801498127
Distinct label vectors: 26

INFO Fitting model to 534 training examples...
DEBUG A dense matrix is used to store the feature values of the training examples
DEBUG A dense matrix is used to store the labels of the training examples
INFO Successfully fit model in 0.3274696630001017 seconds
INFO Fold 10 / 10:
INFO Data characteristics for experiment "boomer" (Fold 10):

Examples: 534
Features: 72 (72 numerical, 0 nominal)
Feature density: 0.9967488555971702
Feature sparsity: 0.0032511444028298087
Labels: 6
Label density: 0.3114856429463171
Label sparsity: 0.6885143570536829
Label imbalance ratio: 1.4910311517318968
Label cardinality: 1.8689138576779025
Distinct label vectors: 27

INFO Fitting model to 534 training examples...
DEBUG A dense matrix is used to store the feature values of the training examples
DEBUG A dense matrix is used to store the labels of the training examples
INFO Successfully fit model in 0.3189453660002073 seconds
INFO Successfully finished after 3.290168752000227 seconds