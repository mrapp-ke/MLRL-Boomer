mlrl-testbed mlrl.boosting --log-level debug --data-dir python/tests/res/data --dataset emotions --output-dir python/tests/res/tmp/results --store-evaluation true --prediction-type scores --incremental-evaluation true{step_size=50} --print-evaluation true --store-evaluation true
INFO Starting experiment using the classification algorithm "BoomerClassifier"...
INFO Using separate training and test sets...
DEBUG Reading input data from file "python/tests/res/data/emotions.arff"...
DEBUG Parsing meta-data from file "python/tests/res/data/emotions.xml"...
INFO Fitting model to 397 training examples...
DEBUG A dense matrix is used to store the feature values of the training examples
DEBUG A dense matrix is used to store the labels of the training examples
INFO Successfully fit model in <duration>
DEBUG A dense matrix is used to store the feature values of the query examples
DEBUG A dense matrix is used to store the predicted scores
INFO Predicting for 196 test examples using a model of size 50...
INFO Successfully predicted in <duration>
INFO Evaluation result for test data using a model of size 50:

Coverage Error                    2.81
Discounted Cumulative Gain        1.38
Label Ranking Average Precision   0.81
Mean Absolute Error               1.66
Mean Absolute Percentage Error    5.81937e+15
Mean Squared Error                4.02
Median Absolute Error             1.5
NDCG                             87.61
Ranking Loss                      0.15

DEBUG Writing output data to file "python/tests/res/tmp/results/evaluation_test.csv"...
INFO Predicting for 196 test examples using a model of size 100...
INFO Successfully predicted in <duration>
INFO Evaluation result for test data using a model of size 100:

Coverage Error                    2.81
Discounted Cumulative Gain        1.37
Label Ranking Average Precision   0.81
Mean Absolute Error               1.98
Mean Absolute Percentage Error    7.05313e+15
Mean Squared Error                5.87
Median Absolute Error             1.73
NDCG                             87.25
Ranking Loss                      0.16

DEBUG Writing output data to file "python/tests/res/tmp/results/evaluation_test.csv"...
INFO Predicting for 196 test examples using a model of size 150...
INFO Successfully predicted in <duration>
INFO Evaluation result for test data using a model of size 150:

Coverage Error                    2.76
Discounted Cumulative Gain        1.38
Label Ranking Average Precision   0.82
Mean Absolute Error               2.2
Mean Absolute Percentage Error    7.85646e+15
Mean Squared Error                7.23
Median Absolute Error             1.93
NDCG                             87.74
Ranking Loss                      0.15

DEBUG Writing output data to file "python/tests/res/tmp/results/evaluation_test.csv"...
INFO Predicting for 196 test examples using a model of size 200...
INFO Successfully predicted in <duration>
INFO Evaluation result for test data using a model of size 200:

Coverage Error                    2.73
Discounted Cumulative Gain        1.38
Label Ranking Average Precision   0.82
Mean Absolute Error               2.4
Mean Absolute Percentage Error    8.62146e+15
Mean Squared Error                8.72
Median Absolute Error             2.17
NDCG                             87.86
Ranking Loss                      0.14

DEBUG Writing output data to file "python/tests/res/tmp/results/evaluation_test.csv"...
INFO Predicting for 196 test examples using a model of size 250...
INFO Successfully predicted in <duration>
INFO Evaluation result for test data using a model of size 250:

Coverage Error                    2.71
Discounted Cumulative Gain        1.39
Label Ranking Average Precision   0.83
Mean Absolute Error               2.59
Mean Absolute Percentage Error    9.28529e+15
Mean Squared Error               10.14
Median Absolute Error             2.29
NDCG                             88.34
Ranking Loss                      0.14

DEBUG Writing output data to file "python/tests/res/tmp/results/evaluation_test.csv"...
INFO Predicting for 196 test examples using a model of size 300...
INFO Successfully predicted in <duration>
INFO Evaluation result for test data using a model of size 300:

Coverage Error                    2.74
Discounted Cumulative Gain        1.39
Label Ranking Average Precision   0.82
Mean Absolute Error               2.77
Mean Absolute Percentage Error    9.89841e+15
Mean Squared Error               11.54
Median Absolute Error             2.45
NDCG                             88.15
Ranking Loss                      0.15

DEBUG Writing output data to file "python/tests/res/tmp/results/evaluation_test.csv"...
INFO Predicting for 196 test examples using a model of size 350...
INFO Successfully predicted in <duration>
INFO Evaluation result for test data using a model of size 350:

Coverage Error                    2.73
Discounted Cumulative Gain        1.39
Label Ranking Average Precision   0.83
Mean Absolute Error               2.94
Mean Absolute Percentage Error    1.05462e+16
Mean Squared Error               13.06
Median Absolute Error             2.55
NDCG                             88.66
Ranking Loss                      0.14

DEBUG Writing output data to file "python/tests/res/tmp/results/evaluation_test.csv"...
INFO Predicting for 196 test examples using a model of size 400...
INFO Successfully predicted in <duration>
INFO Evaluation result for test data using a model of size 400:

Coverage Error                    2.71
Discounted Cumulative Gain        1.39
Label Ranking Average Precision   0.83
Mean Absolute Error               3.08
Mean Absolute Percentage Error    1.10423e+16
Mean Squared Error               14.31
Median Absolute Error             2.73
NDCG                             88.87
Ranking Loss                      0.14

DEBUG Writing output data to file "python/tests/res/tmp/results/evaluation_test.csv"...
INFO Predicting for 196 test examples using a model of size 450...
INFO Successfully predicted in <duration>
INFO Evaluation result for test data using a model of size 450:

Coverage Error                    2.71
Discounted Cumulative Gain        1.39
Label Ranking Average Precision   0.83
Mean Absolute Error               3.23
Mean Absolute Percentage Error    1.15868e+16
Mean Squared Error               15.7
Median Absolute Error             2.86
NDCG                             88.8
Ranking Loss                      0.14

DEBUG Writing output data to file "python/tests/res/tmp/results/evaluation_test.csv"...
INFO Predicting for 196 test examples using a model of size 500...
INFO Successfully predicted in <duration>
INFO Evaluation result for test data using a model of size 500:

Coverage Error                    2.72
Discounted Cumulative Gain        1.39
Label Ranking Average Precision   0.83
Mean Absolute Error               3.38
Mean Absolute Percentage Error    1.21004e+16
Mean Squared Error               17.05
Median Absolute Error             3.03
NDCG                             88.73
Ranking Loss                      0.14

DEBUG Writing output data to file "python/tests/res/tmp/results/evaluation_test.csv"...
INFO Predicting for 196 test examples using a model of size 550...
INFO Successfully predicted in <duration>
INFO Evaluation result for test data using a model of size 550:

Coverage Error                    2.72
Discounted Cumulative Gain        1.39
Label Ranking Average Precision   0.83
Mean Absolute Error               3.49
Mean Absolute Percentage Error    1.24781e+16
Mean Squared Error               18.1
Median Absolute Error             3.12
NDCG                             88.45
Ranking Loss                      0.14

DEBUG Writing output data to file "python/tests/res/tmp/results/evaluation_test.csv"...
INFO Predicting for 196 test examples using a model of size 600...
INFO Successfully predicted in <duration>
INFO Evaluation result for test data using a model of size 600:

Coverage Error                    2.7
Discounted Cumulative Gain        1.39
Label Ranking Average Precision   0.83
Mean Absolute Error               3.63
Mean Absolute Percentage Error    1.29864e+16
Mean Squared Error               19.6
Median Absolute Error             3.26
NDCG                             88.58
Ranking Loss                      0.14

DEBUG Writing output data to file "python/tests/res/tmp/results/evaluation_test.csv"...
INFO Predicting for 196 test examples using a model of size 650...
INFO Successfully predicted in <duration>
INFO Evaluation result for test data using a model of size 650:

Coverage Error                    2.72
Discounted Cumulative Gain        1.39
Label Ranking Average Precision   0.83
Mean Absolute Error               3.73
Mean Absolute Percentage Error    1.33435e+16
Mean Squared Error               20.66
Median Absolute Error             3.33
NDCG                             88.53
Ranking Loss                      0.14

DEBUG Writing output data to file "python/tests/res/tmp/results/evaluation_test.csv"...
INFO Predicting for 196 test examples using a model of size 700...
INFO Successfully predicted in <duration>
INFO Evaluation result for test data using a model of size 700:

Coverage Error                    2.72
Discounted Cumulative Gain        1.39
Label Ranking Average Precision   0.83
Mean Absolute Error               3.83
Mean Absolute Percentage Error    1.36925e+16
Mean Squared Error               21.75
Median Absolute Error             3.41
NDCG                             88.34
Ranking Loss                      0.14

DEBUG Writing output data to file "python/tests/res/tmp/results/evaluation_test.csv"...
INFO Predicting for 196 test examples using a model of size 750...
INFO Successfully predicted in <duration>
INFO Evaluation result for test data using a model of size 750:

Coverage Error                    2.69
Discounted Cumulative Gain        1.39
Label Ranking Average Precision   0.83
Mean Absolute Error               3.91
Mean Absolute Percentage Error    1.39982e+16
Mean Squared Error               22.7
Median Absolute Error             3.51
NDCG                             88.56
Ranking Loss                      0.14

DEBUG Writing output data to file "python/tests/res/tmp/results/evaluation_test.csv"...
INFO Predicting for 196 test examples using a model of size 800...
INFO Successfully predicted in <duration>
INFO Evaluation result for test data using a model of size 800:

Coverage Error                    2.7
Discounted Cumulative Gain        1.39
Label Ranking Average Precision   0.83
Mean Absolute Error               4
Mean Absolute Percentage Error    1.43054e+16
Mean Squared Error               23.71
Median Absolute Error             3.58
NDCG                             88.63
Ranking Loss                      0.14

DEBUG Writing output data to file "python/tests/res/tmp/results/evaluation_test.csv"...
INFO Predicting for 196 test examples using a model of size 850...
INFO Successfully predicted in <duration>
INFO Evaluation result for test data using a model of size 850:

Coverage Error                    2.7
Discounted Cumulative Gain        1.39
Label Ranking Average Precision   0.83
Mean Absolute Error               4.07
Mean Absolute Percentage Error    1.4562e+16
Mean Squared Error               24.55
Median Absolute Error             3.67
NDCG                             88.55
Ranking Loss                      0.14

DEBUG Writing output data to file "python/tests/res/tmp/results/evaluation_test.csv"...
INFO Predicting for 196 test examples using a model of size 900...
INFO Successfully predicted in <duration>
INFO Evaluation result for test data using a model of size 900:

Coverage Error                    2.69
Discounted Cumulative Gain        1.39
Label Ranking Average Precision   0.83
Mean Absolute Error               4.14
Mean Absolute Percentage Error    1.48147e+16
Mean Squared Error               25.42
Median Absolute Error             3.73
NDCG                             88.47
Ranking Loss                      0.14

DEBUG Writing output data to file "python/tests/res/tmp/results/evaluation_test.csv"...
INFO Predicting for 196 test examples using a model of size 950...
INFO Successfully predicted in <duration>
INFO Evaluation result for test data using a model of size 950:

Coverage Error                    2.69
Discounted Cumulative Gain        1.39
Label Ranking Average Precision   0.83
Mean Absolute Error               4.23
Mean Absolute Percentage Error    1.51054e+16
Mean Squared Error               26.41
Median Absolute Error             3.81
NDCG                             88.57
Ranking Loss                      0.14

DEBUG Writing output data to file "python/tests/res/tmp/results/evaluation_test.csv"...
INFO Predicting for 196 test examples using a model of size 1000...
INFO Successfully predicted in <duration>
INFO Evaluation result for test data using a model of size 1000:

Coverage Error                    2.69
Discounted Cumulative Gain        1.39
Label Ranking Average Precision   0.83
Mean Absolute Error               4.29
Mean Absolute Percentage Error    1.5319e+16
Mean Squared Error               27.18
Median Absolute Error             3.91
NDCG                             88.65
Ranking Loss                      0.14

DEBUG Writing output data to file "python/tests/res/tmp/results/evaluation_test.csv"...
INFO Successfully finished after <duration>
