mlrl-testbed mlrl.boosting --log-level debug --base-dir python/tests/res/tmp --data-dir python/tests/res/data --dataset emotions --result-dir results --save-evaluation true --instance-sampling without-replacement --rule-pruning irep
Checking if output files do already exist...
Starting experiment using the classification algorithm "BoomerClassifier"...
DEBUG: Writing output data to file "python/tests/res/tmp/metadata.yml"...
Using separate training and test sets...
DEBUG: Reading input data from file "python/tests/res/data/emotions.arff"...
DEBUG: Parsing meta-data from file "python/tests/res/data/emotions.xml"...
Fitting model to 397 training examples...
DEBUG: A dense matrix is used to store the feature values of the training examples
DEBUG: A dense matrix is used to store the labels of the training examples
Successfully fit model in <duration>
Predicting for 196 test examples...
DEBUG: A dense matrix is used to store the feature values of the query examples
DEBUG: A dense matrix is used to store the predicted labels
Successfully predicted in <duration>
Evaluation result for test data:

Example-wise F1 (↑)         61.63
Example-wise Jaccard (↑)    53.74
Example-wise Precision (↑)  79.59
Example-wise Recall (↑)     61.39
Hamming Accuracy (↑)        81.55
Hamming Loss (↓)            18.45
Macro F1 (↑)                65.96
Macro Jaccard (↑)           49.83
Macro Precision (↑)         77.18
Macro Recall (↑)            58.61
Micro F1 (↑)                67.56
Micro Jaccard (↑)           51.02
Micro Precision (↑)         76.87
Micro Recall (↑)            60.27
Subset 0/1 Loss (↓)         71.43
Subset Accuracy (↑)         28.57

DEBUG: Writing output data to file "python/tests/res/tmp/results/evaluation_test.csv"...
Successfully finished experiment after <duration>
