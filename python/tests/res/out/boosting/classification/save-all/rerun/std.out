mlrl-testbed mlrl.boosting --mode read --log-level debug --base-dir python/tests/res/tmp/rerun --input-dir python/tests/res/tmp --save-evaluation true --save-all true
Reading meta-data...
Reading input data from file "python/tests/res/tmp/metadata.yml"...
Successfully read meta-data
Checking for version conflicts...
Experimental results have been created with version "<version>" of the package "mlrl-testbed", version "<version>" is currently used
No version conflicts detected
Reading experimental results of 1 experiment...

Reading experimental results of experiment (1 / 1)...
The command "mlrl-testbed mlrl.boosting --log-level debug --base-dir python/tests/res/tmp --data-dir python/tests/res/data --dataset emotions --result-dir results --save-evaluation true --save-all true --model-save-dir models --parameter-save-dir results" has been used originally for running this experiment
Using separate training and test sets...
Reading input data from file "python/tests/res/tmp/results/data_characteristics.csv"...
Reading input data from file "python/tests/res/tmp/results/evaluation_test.csv"...
Reading input data from file "python/tests/res/tmp/results/joint_probability_calibration_model.csv"...
The file "python/tests/res/tmp/results/joint_probability_calibration_model.csv" does not exist
Reading input data from file "python/tests/res/tmp/results/label_vectors.csv"...
Reading input data from file "python/tests/res/tmp/results/marginal_probability_calibration_model.csv"...
The file "python/tests/res/tmp/results/marginal_probability_calibration_model.csv" does not exist
Reading input data from file "python/tests/res/tmp/results/prediction_characteristics_test.csv"...
Reading input data from file "python/tests/res/tmp/results/predictions_test.arff"...
Parsing meta-data from file "python/tests/res/tmp/results/predictions_test.xml"...
Reading input data from file "python/tests/res/tmp/results/rules.txt"...
Reading input data from file "python/tests/res/tmp/results/model_characteristics.csv"...
Reading input data from file "python/tests/res/tmp/models/model.pickle"...
Successfully loaded model
Reading input data from file "python/tests/res/tmp/results/parameters.csv"...
Writing output data to file "python/tests/res/tmp/rerun/results/data_characteristics.csv"...
Writing output data to file "python/tests/res/tmp/rerun/results/parameters.csv"...
Evaluation result for test data:

Example-wise F1 (↑)         62.77
Example-wise Jaccard (↑)    55.06
Example-wise Precision (↑)  78.06
Example-wise Recall (↑)     62.41
Hamming Accuracy (↑)        81.21
Hamming Loss (↓)            18.79
Macro F1 (↑)                64.89
Macro Jaccard (↑)           49.26
Macro Precision (↑)         75.68
Macro Recall (↑)            60.15
Micro F1 (↑)                67.64
Micro Jaccard (↑)           51.11
Micro Precision (↑)         75
Micro Recall (↑)            61.6
Subset 0/1 Loss (↓)         69.39
Subset Accuracy (↑)         30.61

Writing output data to file "python/tests/res/tmp/rerun/results/evaluation_test.csv"...
Writing output data to file "python/tests/res/tmp/rerun/results/prediction_characteristics_test.csv"...
Writing output data to file "python/tests/res/tmp/rerun/results/predictions_test.arff"...
Writing output data to file "python/tests/res/tmp/rerun/results/joint_probability_calibration_model.csv"...
Writing output data to file "python/tests/res/tmp/rerun/results/label_vectors.csv"...
Writing output data to file "python/tests/res/tmp/rerun/results/marginal_probability_calibration_model.csv"...
Writing output data to file "python/tests/res/tmp/rerun/models/model.pickle"...
Writing output data to file "python/tests/res/tmp/rerun/results/rules.txt"...
Writing output data to file "python/tests/res/tmp/rerun/results/model_characteristics.csv"...
