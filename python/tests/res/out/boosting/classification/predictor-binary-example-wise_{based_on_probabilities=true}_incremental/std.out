mlrl-testbed mlrl.boosting --log-level debug --base-dir python/tests/res/tmp --data-dir python/tests/res/data --dataset emotions --result-dir results --save-evaluation true --marginal-probability-calibration isotonic --print-marginal-probability-calibration-model true --save-marginal-probability-calibration-model true --joint-probability-calibration isotonic --print-joint-probability-calibration-model true --save-joint-probability-calibration-model true --binary-predictor example-wise{based_on_probabilities=true} --incremental-evaluation true{step_size=50} --print-evaluation true --save-evaluation true --save-models true --load-models true --model-load-dir models --model-save-dir models
Checking if output files do already exist...
Starting experiment using the classification algorithm "BoomerClassifier"...
DEBUG: Writing output data to file "python/tests/res/tmp/metadata.yml"...
Using separate training and test sets...
DEBUG: Reading input data from file "python/tests/res/data/emotions.arff"...
DEBUG: Parsing meta-data from file "python/tests/res/data/emotions.xml"...
DEBUG: Reading input data from file "models/model.pickle"...
ERROR: The file "models/model.pickle" does not exist
Fitting model to 397 training examples...
DEBUG: A dense matrix is used to store the feature values of the training examples
DEBUG: A dense matrix is used to store the labels of the training examples
Successfully fit model in <duration>
DEBUG: A dense matrix is used to store the feature values of the query examples
DEBUG: A dense matrix is used to store the predicted labels
Predicting for 196 test examples using a model of size 50...
Successfully predicted in <duration>
Evaluation result for test data using a model of size 50:

Example-wise F1 (↑)         35.97
Example-wise Jaccard (↑)    29.25
Example-wise Precision (↑)  48.98
Example-wise Recall (↑)     30.27
Hamming Accuracy (↑)        68.54
Hamming Loss (↓)            31.46
Macro F1 (↑)                29.09
Macro Jaccard (↑)           18.19
Macro Precision (↑)         70.37
Macro Recall (↑)            28.13
Micro F1 (↑)                37.07
Micro Jaccard (↑)           22.76
Micro Precision (↑)         51.17
Micro Recall (↑)            29.07
Subset 0/1 Loss (↓)         90.31
Subset Accuracy (↑)          9.69

DEBUG: Writing output data to file "python/tests/res/tmp/results/evaluation_test.csv"...
Predicting for 196 test examples using a model of size 100...
Successfully predicted in <duration>
Evaluation result for test data using a model of size 100:

Example-wise F1 (↑)         42.35
Example-wise Jaccard (↑)    34.99
Example-wise Precision (↑)  55.36
Example-wise Recall (↑)     36.73
Hamming Accuracy (↑)        71.51
Hamming Loss (↓)            28.49
Macro F1 (↑)                42.15
Macro Jaccard (↑)           27.62
Macro Precision (↑)         69.03
Macro Recall (↑)            35.8
Micro F1 (↑)                44.81
Micro Jaccard (↑)           28.87
Micro Precision (↑)         58.62
Micro Recall (↑)            36.27
Subset 0/1 Loss (↓)         86.73
Subset Accuracy (↑)         13.27

DEBUG: Writing output data to file "python/tests/res/tmp/results/evaluation_test.csv"...
Predicting for 196 test examples using a model of size 150...
Successfully predicted in <duration>
Evaluation result for test data using a model of size 150:

Example-wise F1 (↑)         46.28
Example-wise Jaccard (↑)    38.22
Example-wise Precision (↑)  59.69
Example-wise Recall (↑)     40.73
Hamming Accuracy (↑)        72.79
Hamming Loss (↓)            27.21
Macro F1 (↑)                45.84
Macro Jaccard (↑)           30.51
Macro Precision (↑)         68.4
Macro Recall (↑)            38.33
Micro F1 (↑)                47.88
Micro Jaccard (↑)           31.48
Micro Precision (↑)         61.51
Micro Recall (↑)            39.2
Subset 0/1 Loss (↓)         84.69
Subset Accuracy (↑)         15.31

DEBUG: Writing output data to file "python/tests/res/tmp/results/evaluation_test.csv"...
Predicting for 196 test examples using a model of size 200...
Successfully predicted in <duration>
Evaluation result for test data using a model of size 200:

Example-wise F1 (↑)         51.02
Example-wise Jaccard (↑)    42.6
Example-wise Precision (↑)  65.56
Example-wise Recall (↑)     44.64
Hamming Accuracy (↑)        74.83
Hamming Loss (↓)            25.17
Macro F1 (↑)                50.95
Macro Jaccard (↑)           34.95
Macro Precision (↑)         69.17
Macro Recall (↑)            42.78
Micro F1 (↑)                52.41
Micro Jaccard (↑)           35.51
Micro Precision (↑)         65.99
Micro Recall (↑)            43.47
Subset 0/1 Loss (↓)         82.14
Subset Accuracy (↑)         17.86

DEBUG: Writing output data to file "python/tests/res/tmp/results/evaluation_test.csv"...
Predicting for 196 test examples using a model of size 250...
Successfully predicted in <duration>
Evaluation result for test data using a model of size 250:

Example-wise F1 (↑)         51.12
Example-wise Jaccard (↑)    42.86
Example-wise Precision (↑)  65.56
Example-wise Recall (↑)     44.9
Hamming Accuracy (↑)        74.32
Hamming Loss (↓)            25.68
Macro F1 (↑)                50.68
Macro Jaccard (↑)           34.42
Macro Precision (↑)         66.2
Macro Recall (↑)            42.79
Micro F1 (↑)                52.06
Micro Jaccard (↑)           35.19
Micro Precision (↑)         64.31
Micro Recall (↑)            43.73
Subset 0/1 Loss (↓)         81.12
Subset Accuracy (↑)         18.88

DEBUG: Writing output data to file "python/tests/res/tmp/results/evaluation_test.csv"...
Predicting for 196 test examples using a model of size 300...
Successfully predicted in <duration>
Evaluation result for test data using a model of size 300:

Example-wise F1 (↑)         51.51
Example-wise Jaccard (↑)    42.98
Example-wise Precision (↑)  65.22
Example-wise Recall (↑)     45.92
Hamming Accuracy (↑)        74.06
Hamming Loss (↓)            25.94
Macro F1 (↑)                51.14
Macro Jaccard (↑)           34.97
Macro Precision (↑)         62.44
Macro Recall (↑)            44.52
Micro F1 (↑)                53
Micro Jaccard (↑)           36.06
Micro Precision (↑)         62.77
Micro Recall (↑)            45.87
Subset 0/1 Loss (↓)         82.14
Subset Accuracy (↑)         17.86

DEBUG: Writing output data to file "python/tests/res/tmp/results/evaluation_test.csv"...
Predicting for 196 test examples using a model of size 350...
Successfully predicted in <duration>
Evaluation result for test data using a model of size 350:

Example-wise F1 (↑)         51.05
Example-wise Jaccard (↑)    42.35
Example-wise Precision (↑)  64.63
Example-wise Recall (↑)     45.58
Hamming Accuracy (↑)        73.38
Hamming Loss (↓)            26.62
Macro F1 (↑)                50.28
Macro Jaccard (↑)           34.16
Macro Precision (↑)         60.34
Macro Recall (↑)            44.24
Micro F1 (↑)                52.21
Micro Jaccard (↑)           35.33
Micro Precision (↑)         61.07
Micro Recall (↑)            45.6
Subset 0/1 Loss (↓)         83.16
Subset Accuracy (↑)         16.84

DEBUG: Writing output data to file "python/tests/res/tmp/results/evaluation_test.csv"...
Predicting for 196 test examples using a model of size 400...
Successfully predicted in <duration>
Evaluation result for test data using a model of size 400:

Example-wise F1 (↑)         50.85
Example-wise Jaccard (↑)    41.96
Example-wise Precision (↑)  64.97
Example-wise Recall (↑)     45.07
Hamming Accuracy (↑)        73.38
Hamming Loss (↓)            26.62
Macro F1 (↑)                50
Macro Jaccard (↑)           33.99
Macro Precision (↑)         60.12
Macro Recall (↑)            44.07
Micro F1 (↑)                52.07
Micro Jaccard (↑)           35.2
Micro Precision (↑)         61.15
Micro Recall (↑)            45.33
Subset 0/1 Loss (↓)         84.18
Subset Accuracy (↑)         15.82

DEBUG: Writing output data to file "python/tests/res/tmp/results/evaluation_test.csv"...
Predicting for 196 test examples using a model of size 450...
Successfully predicted in <duration>
Evaluation result for test data using a model of size 450:

Example-wise F1 (↑)         50.75
Example-wise Jaccard (↑)    41.79
Example-wise Precision (↑)  64.8
Example-wise Recall (↑)     45.07
Hamming Accuracy (↑)        73.04
Hamming Loss (↓)            26.96
Macro F1 (↑)                49.65
Macro Jaccard (↑)           33.57
Macro Precision (↑)         59.76
Macro Recall (↑)            43.86
Micro F1 (↑)                51.75
Micro Jaccard (↑)           34.91
Micro Precision (↑)         60.28
Micro Recall (↑)            45.33
Subset 0/1 Loss (↓)         84.69
Subset Accuracy (↑)         15.31

DEBUG: Writing output data to file "python/tests/res/tmp/results/evaluation_test.csv"...
Predicting for 196 test examples using a model of size 500...
Successfully predicted in <duration>
Evaluation result for test data using a model of size 500:

Example-wise F1 (↑)         51.14
Example-wise Jaccard (↑)    42.13
Example-wise Precision (↑)  64.37
Example-wise Recall (↑)     45.75
Hamming Accuracy (↑)        72.79
Hamming Loss (↓)            27.21
Macro F1 (↑)                50.46
Macro Jaccard (↑)           34.1
Macro Precision (↑)         59.71
Macro Recall (↑)            45.33
Micro F1 (↑)                52.24
Micro Jaccard (↑)           35.35
Micro Precision (↑)         59.32
Micro Recall (↑)            46.67
Subset 0/1 Loss (↓)         84.69
Subset Accuracy (↑)         15.31

DEBUG: Writing output data to file "python/tests/res/tmp/results/evaluation_test.csv"...
Predicting for 196 test examples using a model of size 550...
Successfully predicted in <duration>
Evaluation result for test data using a model of size 550:

Example-wise F1 (↑)         50.37
Example-wise Jaccard (↑)    41.54
Example-wise Precision (↑)  63.95
Example-wise Recall (↑)     44.9
Hamming Accuracy (↑)        72.28
Hamming Loss (↓)            27.72
Macro F1 (↑)                49.25
Macro Jaccard (↑)           33.06
Macro Precision (↑)         58.88
Macro Recall (↑)            44.33
Micro F1 (↑)                51.2
Micro Jaccard (↑)           34.41
Micro Precision (↑)         58.36
Micro Recall (↑)            45.6
Subset 0/1 Loss (↓)         84.69
Subset Accuracy (↑)         15.31

DEBUG: Writing output data to file "python/tests/res/tmp/results/evaluation_test.csv"...
Predicting for 196 test examples using a model of size 600...
Successfully predicted in <duration>
Evaluation result for test data using a model of size 600:

Example-wise F1 (↑)         51.29
Example-wise Jaccard (↑)    42.39
Example-wise Precision (↑)  64.29
Example-wise Recall (↑)     46
Hamming Accuracy (↑)        72.62
Hamming Loss (↓)            27.38
Macro F1 (↑)                50.54
Macro Jaccard (↑)           34.19
Macro Precision (↑)         59.11
Macro Recall (↑)            45.75
Micro F1 (↑)                52.23
Micro Jaccard (↑)           35.34
Micro Precision (↑)         58.86
Micro Recall (↑)            46.93
Subset 0/1 Loss (↓)         84.18
Subset Accuracy (↑)         15.82

DEBUG: Writing output data to file "python/tests/res/tmp/results/evaluation_test.csv"...
Predicting for 196 test examples using a model of size 650...
Successfully predicted in <duration>
Evaluation result for test data using a model of size 650:

Example-wise F1 (↑)         47.21
Example-wise Jaccard (↑)    38.82
Example-wise Precision (↑)  58.93
Example-wise Recall (↑)     42.69
Hamming Accuracy (↑)        69.73
Hamming Loss (↓)            30.27
Macro F1 (↑)                46.19
Macro Jaccard (↑)           30.36
Macro Precision (↑)         54.07
Macro Recall (↑)            42.79
Micro F1 (↑)                48.1
Micro Jaccard (↑)           31.67
Micro Precision (↑)         53.05
Micro Recall (↑)            44
Subset 0/1 Loss (↓)         86.22
Subset Accuracy (↑)         13.78

DEBUG: Writing output data to file "python/tests/res/tmp/results/evaluation_test.csv"...
Predicting for 196 test examples using a model of size 700...
Successfully predicted in <duration>
Evaluation result for test data using a model of size 700:

Example-wise F1 (↑)         47.59
Example-wise Jaccard (↑)    39.29
Example-wise Precision (↑)  59.27
Example-wise Recall (↑)     43.03
Hamming Accuracy (↑)        69.64
Hamming Loss (↓)            30.36
Macro F1 (↑)                46.51
Macro Jaccard (↑)           30.57
Macro Precision (↑)         54.47
Macro Recall (↑)            43.17
Micro F1 (↑)                48.19
Micro Jaccard (↑)           31.74
Micro Precision (↑)         52.87
Micro Recall (↑)            44.27
Subset 0/1 Loss (↓)         85.2
Subset Accuracy (↑)         14.8

DEBUG: Writing output data to file "python/tests/res/tmp/results/evaluation_test.csv"...
Predicting for 196 test examples using a model of size 750...
Successfully predicted in <duration>
Evaluation result for test data using a model of size 750:

Example-wise F1 (↑)         46.79
Example-wise Jaccard (↑)    38.65
Example-wise Precision (↑)  58.42
Example-wise Recall (↑)     42.18
Hamming Accuracy (↑)        68.62
Hamming Loss (↓)            31.38
Macro F1 (↑)                44.76
Macro Jaccard (↑)           29.12
Macro Precision (↑)         53.53
Macro Recall (↑)            42.16
Micro F1 (↑)                46.91
Micro Jaccard (↑)           30.64
Micro Precision (↑)         50.94
Micro Recall (↑)            43.47
Subset 0/1 Loss (↓)         85.2
Subset Accuracy (↑)         14.8

DEBUG: Writing output data to file "python/tests/res/tmp/results/evaluation_test.csv"...
Predicting for 196 test examples using a model of size 800...
Successfully predicted in <duration>
Evaluation result for test data using a model of size 800:

Example-wise F1 (↑)         47.35
Example-wise Jaccard (↑)    39.16
Example-wise Precision (↑)  58.59
Example-wise Recall (↑)     43.2
Hamming Accuracy (↑)        68.79
Hamming Loss (↓)            31.21
Macro F1 (↑)                45.3
Macro Jaccard (↑)           29.61
Macro Precision (↑)         53.62
Macro Recall (↑)            42.93
Micro F1 (↑)                47.5
Micro Jaccard (↑)           31.14
Micro Precision (↑)         51.23
Micro Recall (↑)            44.27
Subset 0/1 Loss (↓)         85.2
Subset Accuracy (↑)         14.8

DEBUG: Writing output data to file "python/tests/res/tmp/results/evaluation_test.csv"...
Predicting for 196 test examples using a model of size 850...
Successfully predicted in <duration>
Evaluation result for test data using a model of size 850:

Example-wise F1 (↑)         47.07
Example-wise Jaccard (↑)    38.99
Example-wise Precision (↑)  58.16
Example-wise Recall (↑)     42.94
Hamming Accuracy (↑)        68.71
Hamming Loss (↓)            31.29
Macro F1 (↑)                45.06
Macro Jaccard (↑)           29.45
Macro Precision (↑)         53.46
Macro Recall (↑)            42.83
Micro F1 (↑)                47.43
Micro Jaccard (↑)           31.09
Micro Precision (↑)         51.08
Micro Recall (↑)            44.27
Subset 0/1 Loss (↓)         85.2
Subset Accuracy (↑)         14.8

DEBUG: Writing output data to file "python/tests/res/tmp/results/evaluation_test.csv"...
Predicting for 196 test examples using a model of size 900...
Successfully predicted in <duration>
Evaluation result for test data using a model of size 900:

Example-wise F1 (↑)         46.56
Example-wise Jaccard (↑)    38.48
Example-wise Precision (↑)  57.65
Example-wise Recall (↑)     42.43
Hamming Accuracy (↑)        68.45
Hamming Loss (↓)            31.55
Macro F1 (↑)                44.4
Macro Jaccard (↑)           28.96
Macro Precision (↑)         52.7
Macro Recall (↑)            42.46
Micro F1 (↑)                47.08
Micro Jaccard (↑)           30.78
Micro Precision (↑)         50.61
Micro Recall (↑)            44
Subset 0/1 Loss (↓)         85.71
Subset Accuracy (↑)         14.29

DEBUG: Writing output data to file "python/tests/res/tmp/results/evaluation_test.csv"...
Predicting for 196 test examples using a model of size 950...
Successfully predicted in <duration>
Evaluation result for test data using a model of size 950:

Example-wise F1 (↑)         47.09
Example-wise Jaccard (↑)    38.99
Example-wise Precision (↑)  58.16
Example-wise Recall (↑)     43.11
Hamming Accuracy (↑)        68.54
Hamming Loss (↓)            31.46
Macro F1 (↑)                44.81
Macro Jaccard (↑)           29.25
Macro Precision (↑)         53.53
Macro Recall (↑)            42.95
Micro F1 (↑)                47.44
Micro Jaccard (↑)           31.1
Micro Precision (↑)         50.76
Micro Recall (↑)            44.53
Subset 0/1 Loss (↓)         85.2
Subset Accuracy (↑)         14.8

DEBUG: Writing output data to file "python/tests/res/tmp/results/evaluation_test.csv"...
Predicting for 196 test examples using a model of size 1000...
Successfully predicted in <duration>
Evaluation result for test data using a model of size 1000:

Example-wise F1 (↑)         46.65
Example-wise Jaccard (↑)    38.56
Example-wise Precision (↑)  57.65
Example-wise Recall (↑)     42.52
Hamming Accuracy (↑)        68.28
Hamming Loss (↓)            31.72
Macro F1 (↑)                44.29
Macro Jaccard (↑)           28.85
Macro Precision (↑)         53.65
Macro Recall (↑)            42.66
Micro F1 (↑)                47.09
Micro Jaccard (↑)           30.8
Micro Precision (↑)         50.3
Micro Recall (↑)            44.27
Subset 0/1 Loss (↓)         85.71
Subset Accuracy (↑)         14.29

DEBUG: Writing output data to file "python/tests/res/tmp/results/evaluation_test.csv"...
Joint probability calibration model:

┌─────────────────────────────┬────────────────────────────────┐
│   Label vector 1 thresholds │   Label vector 1 probabilities │
├─────────────────────────────┼────────────────────────────────┤
│                      0      │                         0      │
│                      0.0021 │                         0.05   │
│                      0.0425 │                         0.198  │
│                      0.427  │                         0.3333 │
│                      0.457  │                         0.4167 │
│                      0.5125 │                         0.6    │
└─────────────────────────────┴────────────────────────────────┘
┌─────────────────────────────┬────────────────────────────────┐
│   Label vector 2 thresholds │   Label vector 2 probabilities │
├─────────────────────────────┼────────────────────────────────┤
│                      0      │                            0   │
│                      0.0392 │                            0.1 │
│                      0.1205 │                            1   │
└─────────────────────────────┴────────────────────────────────┘
┌─────────────────────────────┬────────────────────────────────┐
│   Label vector 3 thresholds │   Label vector 3 probabilities │
├─────────────────────────────┼────────────────────────────────┤
│                      0      │                         0.0044 │
│                      0.0091 │                         0.1667 │
│                      0.0192 │                         0.2344 │
│                      0.1367 │                         0.3125 │
│                      0.339  │                         0.3333 │
└─────────────────────────────┴────────────────────────────────┘
┌─────────────────────────────┬────────────────────────────────┐
│   Label vector 4 thresholds │   Label vector 4 probabilities │
├─────────────────────────────┼────────────────────────────────┤
│                      0      │                         0.005  │
│                      0.0558 │                         0.375  │
│                      0.0721 │                         0.4688 │
│                      0.1606 │                         0.5875 │
│                      0.4129 │                         1      │
└─────────────────────────────┴────────────────────────────────┘
┌─────────────────────────────┬────────────────────────────────┐
│   Label vector 5 thresholds │   Label vector 5 probabilities │
├─────────────────────────────┼────────────────────────────────┤
│                      0      │                         0      │
│                      0.0003 │                         0.0328 │
│                      0.0879 │                         0.3654 │
│                      0.1516 │                         0.5625 │
│                      0.2281 │                         0.8571 │
└─────────────────────────────┴────────────────────────────────┘
┌─────────────────────────────┬────────────────────────────────┐
│   Label vector 6 thresholds │   Label vector 6 probabilities │
├─────────────────────────────┼────────────────────────────────┤
│                      0      │                         0      │
│                      0.0218 │                         0.1667 │
│                      0.0821 │                         0.3333 │
│                      0.1753 │                         0.5    │
│                      0.2483 │                         0.5312 │
└─────────────────────────────┴────────────────────────────────┘
┌─────────────────────────────┬────────────────────────────────┐
│   Label vector 7 thresholds │   Label vector 7 probabilities │
├─────────────────────────────┼────────────────────────────────┤
│                      0      │                           0    │
│                      0.0538 │                           0.04 │
└─────────────────────────────┴────────────────────────────────┘
┌─────────────────────────────┬────────────────────────────────┐
│   Label vector 8 thresholds │   Label vector 8 probabilities │
├─────────────────────────────┼────────────────────────────────┤
│                      0      │                         0.0024 │
│                      0.0016 │                         0.0509 │
│                      0.0397 │                         0.1938 │
│                      0.1581 │                         0.6    │
│                      0.5207 │                         1      │
└─────────────────────────────┴────────────────────────────────┘
┌─────────────────────────────┬────────────────────────────────┐
│   Label vector 9 thresholds │   Label vector 9 probabilities │
├─────────────────────────────┼────────────────────────────────┤
│                      0      │                         0.0012 │
│                      0.0032 │                         0.1615 │
│                      0.0342 │                         0.25   │
│                      0.0649 │                         0.2667 │
│                      0.0929 │                         0.2917 │
│                      0.124  │                         0.3482 │
│                      0.4852 │                         1      │
└─────────────────────────────┴────────────────────────────────┘
┌──────────────────────────────┬─────────────────────────────────┐
│   Label vector 10 thresholds │   Label vector 10 probabilities │
├──────────────────────────────┼─────────────────────────────────┤
│                       0      │                          0.0294 │
│                       0.0001 │                          0.1984 │
│                       0.0894 │                          0.2719 │
│                       0.3225 │                          1      │
└──────────────────────────────┴─────────────────────────────────┘
┌──────────────────────────────┬─────────────────────────────────┐
│   Label vector 11 thresholds │   Label vector 11 probabilities │
├──────────────────────────────┼─────────────────────────────────┤
│                       0      │                          0      │
│                       0.015  │                          0.0794 │
│                       0.0379 │                          0.2    │
│                       0.0567 │                          0.2053 │
└──────────────────────────────┴─────────────────────────────────┘
┌──────────────────────────────┬─────────────────────────────────┐
│   Label vector 12 thresholds │   Label vector 12 probabilities │
├──────────────────────────────┼─────────────────────────────────┤
│                       0      │                          0      │
│                       0.0062 │                          0.0955 │
│                       0.0651 │                          0.1964 │
│                       0.2948 │                          0.4583 │
└──────────────────────────────┴─────────────────────────────────┘
┌──────────────────────────────┬─────────────────────────────────┐
│   Label vector 13 thresholds │   Label vector 13 probabilities │
├──────────────────────────────┼─────────────────────────────────┤
│                       0      │                             0   │
│                       0.2428 │                             0.2 │
└──────────────────────────────┴─────────────────────────────────┘
┌──────────────────────────────┬─────────────────────────────────┐
│   Label vector 14 thresholds │   Label vector 14 probabilities │
├──────────────────────────────┼─────────────────────────────────┤
│                       0      │                          0.0078 │
│                       0      │                          0.2729 │
│                       0.0202 │                          0.2866 │
│                       0.0397 │                          0.3542 │
│                       0.0699 │                          0.4333 │
│                       0.0993 │                          0.5    │
│                       0.1532 │                          0.8889 │
│                       0.2254 │                          1      │
└──────────────────────────────┴─────────────────────────────────┘
┌──────────────────────────────┬─────────────────────────────────┐
│   Label vector 15 thresholds │   Label vector 15 probabilities │
├──────────────────────────────┼─────────────────────────────────┤
│                       0      │                          0.0014 │
│                       0.0022 │                          0.0385 │
│                       0.0166 │                          0.0533 │
│                       0.0618 │                          0.0833 │
└──────────────────────────────┴─────────────────────────────────┘
┌──────────────────────────────┬─────────────────────────────────┐
│   Label vector 16 thresholds │   Label vector 16 probabilities │
├──────────────────────────────┼─────────────────────────────────┤
│                       0      │                          0      │
│                       0.0158 │                          0.0286 │
│                       0.1745 │                          0.5    │
└──────────────────────────────┴─────────────────────────────────┘
┌──────────────────────────────┬─────────────────────────────────┐
│   Label vector 17 thresholds │   Label vector 17 probabilities │
├──────────────────────────────┼─────────────────────────────────┤
│                       0      │                            0    │
│                       0.0416 │                            0.25 │
└──────────────────────────────┴─────────────────────────────────┘
┌──────────────────────────────┬─────────────────────────────────┐
│   Label vector 18 thresholds │   Label vector 18 probabilities │
├──────────────────────────────┼─────────────────────────────────┤
│                            0 │                               0 │
└──────────────────────────────┴─────────────────────────────────┘
┌──────────────────────────────┬─────────────────────────────────┐
│   Label vector 19 thresholds │   Label vector 19 probabilities │
├──────────────────────────────┼─────────────────────────────────┤
│                       0      │                          0      │
│                       0.0397 │                          0.2857 │
│                       0.1934 │                          1      │
└──────────────────────────────┴─────────────────────────────────┘
┌──────────────────────────────┬─────────────────────────────────┐
│   Label vector 20 thresholds │   Label vector 20 probabilities │
├──────────────────────────────┼─────────────────────────────────┤
│                       0      │                           0     │
│                       0.0325 │                           0.125 │
└──────────────────────────────┴─────────────────────────────────┘
┌──────────────────────────────┬─────────────────────────────────┐
│   Label vector 21 thresholds │   Label vector 21 probabilities │
├──────────────────────────────┼─────────────────────────────────┤
│                            0 │                               0 │
└──────────────────────────────┴─────────────────────────────────┘
┌──────────────────────────────┬─────────────────────────────────┐
│   Label vector 22 thresholds │   Label vector 22 probabilities │
├──────────────────────────────┼─────────────────────────────────┤
│                            0 │                               0 │
└──────────────────────────────┴─────────────────────────────────┘
┌──────────────────────────────┬─────────────────────────────────┐
│   Label vector 23 thresholds │   Label vector 23 probabilities │
├──────────────────────────────┼─────────────────────────────────┤
│                       0      │                          0.021  │
│                       0.0137 │                          0.0909 │
│                       0.0508 │                          0.3333 │
│                       0.0643 │                          0.375  │
│                       0.1411 │                          0.5    │
└──────────────────────────────┴─────────────────────────────────┘

DEBUG: Writing output data to file "python/tests/res/tmp/results/joint_probability_calibration_model.csv"...
Marginal probability calibration model:

┌──────────────────────┬─────────────────────────┐
│   Label 1 thresholds │   Label 1 probabilities │
├──────────────────────┼─────────────────────────┤
│               0      │                  0      │
│               0.0006 │                  0.0769 │
│               0.0023 │                  0.0952 │
│               0.0212 │                  0.3042 │
│               0.1312 │                  0.4    │
│               0.2105 │                  0.4417 │
│               0.5997 │                  0.5    │
│               0.6951 │                  0.6333 │
│               0.8326 │                  0.6667 │
│               0.8922 │                  0.875  │
│               0.9603 │                  1      │
└──────────────────────┴─────────────────────────┘
┌──────────────────────┬─────────────────────────┐
│   Label 2 thresholds │   Label 2 probabilities │
├──────────────────────┼─────────────────────────┤
│               0      │                  0      │
│               0.0022 │                  0.2525 │
│               0.0162 │                  0.2694 │
│               0.086  │                  0.3333 │
│               0.1316 │                  0.3479 │
│               0.2913 │                  0.5    │
│               0.3338 │                  0.5238 │
│               0.6828 │                  0.8036 │
│               0.9646 │                  1      │
└──────────────────────┴─────────────────────────┘
┌──────────────────────┬─────────────────────────┐
│   Label 3 thresholds │   Label 3 probabilities │
├──────────────────────┼─────────────────────────┤
│               0      │                  0      │
│               0.0408 │                  0.3333 │
│               0.0923 │                  0.5    │
│               0.5461 │                  0.5042 │
│               0.9957 │                  0.6667 │
│               0.997  │                  1      │
└──────────────────────┴─────────────────────────┘
┌──────────────────────┬─────────────────────────┐
│   Label 4 thresholds │   Label 4 probabilities │
├──────────────────────┼─────────────────────────┤
│               0      │                  0      │
│               0.0003 │                  0.0159 │
│               0.0483 │                  0.2    │
│               0.3111 │                  0.3333 │
│               0.518  │                  0.4167 │
│               0.9344 │                  0.7333 │
│               0.9868 │                  1      │
└──────────────────────┴─────────────────────────┘
┌──────────────────────┬─────────────────────────┐
│   Label 5 thresholds │   Label 5 probabilities │
├──────────────────────┼─────────────────────────┤
│               0.0001 │                  0      │
│               0.0031 │                  0.1849 │
│               0.0202 │                  0.2    │
│               0.0267 │                  0.2306 │
│               0.0679 │                  0.25   │
│               0.1198 │                  0.2946 │
│               0.7024 │                  0.5    │
│               0.953  │                  0.8    │
│               0.9754 │                  1      │
└──────────────────────┴─────────────────────────┘
┌──────────────────────┬─────────────────────────┐
│   Label 6 thresholds │   Label 6 probabilities │
├──────────────────────┼─────────────────────────┤
│               0      │                  0      │
│               0.0011 │                  0.0286 │
│               0.0138 │                  0.1429 │
│               0.0186 │                  0.25   │
│               0.1785 │                  0.5    │
│               0.2218 │                  0.5208 │
│               0.665  │                  0.5312 │
│               0.9485 │                  0.6786 │
│               0.9875 │                  1      │
└──────────────────────┴─────────────────────────┘

DEBUG: Writing output data to file "python/tests/res/tmp/results/marginal_probability_calibration_model.csv"...
DEBUG: Writing output data to file "python/tests/res/tmp/models/model.pickle"...
Successfully finished experiment after <duration>
