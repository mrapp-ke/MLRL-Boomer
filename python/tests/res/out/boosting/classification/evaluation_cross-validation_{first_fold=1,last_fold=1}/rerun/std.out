mlrl-testbed mlrl.boosting --mode read --log-level debug --base-dir python/tests/res/tmp/rerun --input-dir python/tests/res/tmp --save-evaluation true --print-evaluation true --save-evaluation true
Reading meta-data...
Reading input data from file "python/tests/res/tmp/metadata.yml"...
Successfully read meta-data
Checking for version conflicts...
Experimental results have been created with version "<version>" of the package "mlrl-testbed", version "<version>" is currently used
No version conflicts detected
Reading experimental results of 1 experiment...

Reading experimental results of experiment (1 / 1)...
The command "mlrl-testbed mlrl.boosting --log-level debug --base-dir python/tests/res/tmp --data-dir python/tests/res/data --dataset emotions --result-dir results --save-evaluation true --data-split cross-validation{first_fold=1,last_fold=1} --print-evaluation true --save-evaluation true" has been used originally for running this experiment
Performing fold 1 of 10-fold cross validation...
Fold 1 / 10:
Reading input data from file "python/tests/res/tmp/results/evaluation_test_fold-1.csv"...
Evaluation result for test data (Fold 1):

Example-wise F1         64.94
Example-wise Jaccard    57.08
Example-wise Precision  73.61
Example-wise Recall     65.56
Hamming Accuracy        82.22
Hamming Loss            17.78
Macro F1                68.42
Macro Jaccard           53.07
Macro Precision         77.72
Macro Recall            64.44
Micro F1                70.64
Micro Jaccard           54.61
Micro Precision         76.24
Micro Recall            65.81
Subset 0/1 Loss         68.33
Subset Accuracy         31.67

Writing output data to file "python/tests/res/tmp/rerun/results/evaluation_test_fold-1.csv"...
