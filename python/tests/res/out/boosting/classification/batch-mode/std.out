mlrl-testbed mlrl.boosting --mode batch --log-level debug --base-dir python/tests/res/tmp --config python/tests/res/config/boosting/classification/batch_config.yml --save-evaluation true --save-all true
Writing output data to file "python/tests/res/tmp/metadata.yml"...
Running 8 experiments...

Running experiment (1 / 8): "mlrl-testbed mlrl.boosting --base-dir python/tests/res/tmp --data-dir python/tests/res/data --dataset emotions --instance-sampling none --log-level debug --loss logistic-decomposable --model-save-dir instance-sampling_none/loss_logistic-decomposable/dataset_emotions/models --parameter-save-dir instance-sampling_none/loss_logistic-decomposable/dataset_emotions/parameters --result-dir instance-sampling_none/loss_logistic-decomposable/dataset_emotions/results --save-all true --save-evaluation true --save-meta-data false"
Starting experiment using the classification algorithm "BoomerClassifier"...
Using separate training and test sets...
Reading input data from file "python/tests/res/data/emotions.arff"...
Parsing meta-data from file "python/tests/res/data/emotions.xml"...
Writing output data to file "python/tests/res/tmp/instance-sampling_none/loss_logistic-decomposable/dataset_emotions/results/data_characteristics.csv"...
Writing output data to file "python/tests/res/tmp/instance-sampling_none/loss_logistic-decomposable/dataset_emotions/parameters/parameters.csv"...
Fitting model to 397 training examples...
A dense matrix is used to store the feature values of the training examples
A dense matrix is used to store the labels of the training examples
Successfully fit model in <duration>
Predicting for 196 test examples...
A dense matrix is used to store the feature values of the query examples
A dense matrix is used to store the predicted labels
Successfully predicted in <duration>
Evaluation result for test data:

Example-wise F1 (↑)         62.77
Example-wise Jaccard (↑)    55.06
Example-wise Precision (↑)  78.06
Example-wise Recall (↑)     62.41
Hamming Accuracy (↑)        81.21
Hamming Loss (↓)            18.79
Macro F1 (↑)                64.89
Macro Jaccard (↑)           49.26
Macro Precision (↑)         75.68
Macro Recall (↑)            60.15
Micro F1 (↑)                67.64
Micro Jaccard (↑)           51.11
Micro Precision (↑)         75
Micro Recall (↑)            61.6
Subset 0/1 Loss (↓)         69.39
Subset Accuracy (↑)         30.61

Writing output data to file "python/tests/res/tmp/instance-sampling_none/loss_logistic-decomposable/dataset_emotions/results/evaluation_test.csv"...
Writing output data to file "python/tests/res/tmp/instance-sampling_none/loss_logistic-decomposable/dataset_emotions/results/ground_truth_test.arff"...
Writing output data to file "python/tests/res/tmp/instance-sampling_none/loss_logistic-decomposable/dataset_emotions/results/prediction_characteristics_test.csv"...
Writing output data to file "python/tests/res/tmp/instance-sampling_none/loss_logistic-decomposable/dataset_emotions/results/predictions_test.arff"...
Writing output data to file "python/tests/res/tmp/instance-sampling_none/loss_logistic-decomposable/dataset_emotions/results/joint_probability_calibration_model.csv"...
Writing output data to file "python/tests/res/tmp/instance-sampling_none/loss_logistic-decomposable/dataset_emotions/results/label_vectors.csv"...
Writing output data to file "python/tests/res/tmp/instance-sampling_none/loss_logistic-decomposable/dataset_emotions/results/marginal_probability_calibration_model.csv"...
Writing output data to file "python/tests/res/tmp/instance-sampling_none/loss_logistic-decomposable/dataset_emotions/models/model.pickle"...
Writing output data to file "python/tests/res/tmp/instance-sampling_none/loss_logistic-decomposable/dataset_emotions/results/rules.txt"...
Writing output data to file "python/tests/res/tmp/instance-sampling_none/loss_logistic-decomposable/dataset_emotions/results/model_characteristics.csv"...
Successfully finished experiment after <duration>

Running experiment (2 / 8): "mlrl-testbed mlrl.boosting --base-dir python/tests/res/tmp --data-dir python/tests/res/data --dataset emotions --feature-format sparse --instance-sampling none --log-level debug --loss logistic-decomposable --model-save-dir instance-sampling_none/loss_logistic-decomposable/feature-format_sparse/dataset_emotions/models --parameter-save-dir instance-sampling_none/loss_logistic-decomposable/feature-format_sparse/dataset_emotions/parameters --result-dir instance-sampling_none/loss_logistic-decomposable/feature-format_sparse/dataset_emotions/results --save-all true --save-evaluation true --save-meta-data false"
Starting experiment using the classification algorithm "BoomerClassifier"...
Using separate training and test sets...
Reading input data from file "python/tests/res/data/emotions.arff"...
Parsing meta-data from file "python/tests/res/data/emotions.xml"...
Writing output data to file "python/tests/res/tmp/instance-sampling_none/loss_logistic-decomposable/feature-format_sparse/dataset_emotions/results/data_characteristics.csv"...
Writing output data to file "python/tests/res/tmp/instance-sampling_none/loss_logistic-decomposable/feature-format_sparse/dataset_emotions/parameters/parameters.csv"...
Fitting model to 397 training examples...
A sparse matrix with sparse value 0.0 is used to store the feature values of the training examples
A dense matrix is used to store the labels of the training examples
Successfully fit model in <duration>
Predicting for 196 test examples...
A sparse matrix with sparse value 0.0 is used to store the feature values of the query examples
A dense matrix is used to store the predicted labels
Successfully predicted in <duration>
Evaluation result for test data:

Example-wise F1 (↑)         62.13
Example-wise Jaccard (↑)    54.17
Example-wise Precision (↑)  79
Example-wise Recall (↑)     62.41
Hamming Accuracy (↑)        80.95
Hamming Loss (↓)            19.05
Macro F1 (↑)                64.86
Macro Jaccard (↑)           49.06
Macro Precision (↑)         74.09
Macro Recall (↑)            59.17
Micro F1 (↑)                67.06
Micro Jaccard (↑)           50.44
Micro Precision (↑)         74.75
Micro Recall (↑)            60.8
Subset 0/1 Loss (↓)         70.41
Subset Accuracy (↑)         29.59

Writing output data to file "python/tests/res/tmp/instance-sampling_none/loss_logistic-decomposable/feature-format_sparse/dataset_emotions/results/evaluation_test.csv"...
Writing output data to file "python/tests/res/tmp/instance-sampling_none/loss_logistic-decomposable/feature-format_sparse/dataset_emotions/results/ground_truth_test.arff"...
Writing output data to file "python/tests/res/tmp/instance-sampling_none/loss_logistic-decomposable/feature-format_sparse/dataset_emotions/results/prediction_characteristics_test.csv"...
Writing output data to file "python/tests/res/tmp/instance-sampling_none/loss_logistic-decomposable/feature-format_sparse/dataset_emotions/results/predictions_test.arff"...
Writing output data to file "python/tests/res/tmp/instance-sampling_none/loss_logistic-decomposable/feature-format_sparse/dataset_emotions/results/joint_probability_calibration_model.csv"...
Writing output data to file "python/tests/res/tmp/instance-sampling_none/loss_logistic-decomposable/feature-format_sparse/dataset_emotions/results/label_vectors.csv"...
Writing output data to file "python/tests/res/tmp/instance-sampling_none/loss_logistic-decomposable/feature-format_sparse/dataset_emotions/results/marginal_probability_calibration_model.csv"...
Writing output data to file "python/tests/res/tmp/instance-sampling_none/loss_logistic-decomposable/feature-format_sparse/dataset_emotions/models/model.pickle"...
Writing output data to file "python/tests/res/tmp/instance-sampling_none/loss_logistic-decomposable/feature-format_sparse/dataset_emotions/results/rules.txt"...
Writing output data to file "python/tests/res/tmp/instance-sampling_none/loss_logistic-decomposable/feature-format_sparse/dataset_emotions/results/model_characteristics.csv"...
Successfully finished experiment after <duration>

Running experiment (3 / 8): "mlrl-testbed mlrl.boosting --base-dir python/tests/res/tmp --data-dir python/tests/res/data --dataset emotions --instance-sampling with-replacement{sample_size=0.5} --log-level debug --loss logistic-decomposable --model-save-dir instance-sampling_with-replacement{sample_size=0.5}/loss_logistic-decomposable/dataset_emotions/models --parameter-save-dir instance-sampling_with-replacement{sample_size=0.5}/loss_logistic-decomposable/dataset_emotions/parameters --result-dir instance-sampling_with-replacement{sample_size=0.5}/loss_logistic-decomposable/dataset_emotions/results --save-all true --save-evaluation true --save-meta-data false"
Starting experiment using the classification algorithm "BoomerClassifier"...
Using separate training and test sets...
Reading input data from file "python/tests/res/data/emotions.arff"...
Parsing meta-data from file "python/tests/res/data/emotions.xml"...
Writing output data to file "python/tests/res/tmp/instance-sampling_with-replacement{sample_size=0.5}/loss_logistic-decomposable/dataset_emotions/results/data_characteristics.csv"...
Writing output data to file "python/tests/res/tmp/instance-sampling_with-replacement{sample_size=0.5}/loss_logistic-decomposable/dataset_emotions/parameters/parameters.csv"...
Fitting model to 397 training examples...
A dense matrix is used to store the feature values of the training examples
A dense matrix is used to store the labels of the training examples
Successfully fit model in <duration>
Predicting for 196 test examples...
A dense matrix is used to store the feature values of the query examples
A dense matrix is used to store the predicted labels
Successfully predicted in <duration>
Evaluation result for test data:

Example-wise F1 (↑)         61.16
Example-wise Jaccard (↑)    53.1
Example-wise Precision (↑)  77.89
Example-wise Recall (↑)     61.31
Hamming Accuracy (↑)        80.87
Hamming Loss (↓)            19.13
Macro F1 (↑)                65.21
Macro Jaccard (↑)           49.39
Macro Precision (↑)         74.65
Macro Recall (↑)            59.31
Micro F1 (↑)                66.77
Micro Jaccard (↑)           50.11
Micro Precision (↑)         74.83
Micro Recall (↑)            60.27
Subset 0/1 Loss (↓)         72.96
Subset Accuracy (↑)         27.04

Writing output data to file "python/tests/res/tmp/instance-sampling_with-replacement{sample_size=0.5}/loss_logistic-decomposable/dataset_emotions/results/evaluation_test.csv"...
Writing output data to file "python/tests/res/tmp/instance-sampling_with-replacement{sample_size=0.5}/loss_logistic-decomposable/dataset_emotions/results/ground_truth_test.arff"...
Writing output data to file "python/tests/res/tmp/instance-sampling_with-replacement{sample_size=0.5}/loss_logistic-decomposable/dataset_emotions/results/prediction_characteristics_test.csv"...
Writing output data to file "python/tests/res/tmp/instance-sampling_with-replacement{sample_size=0.5}/loss_logistic-decomposable/dataset_emotions/results/predictions_test.arff"...
Writing output data to file "python/tests/res/tmp/instance-sampling_with-replacement{sample_size=0.5}/loss_logistic-decomposable/dataset_emotions/results/joint_probability_calibration_model.csv"...
Writing output data to file "python/tests/res/tmp/instance-sampling_with-replacement{sample_size=0.5}/loss_logistic-decomposable/dataset_emotions/results/label_vectors.csv"...
Writing output data to file "python/tests/res/tmp/instance-sampling_with-replacement{sample_size=0.5}/loss_logistic-decomposable/dataset_emotions/results/marginal_probability_calibration_model.csv"...
Writing output data to file "python/tests/res/tmp/instance-sampling_with-replacement{sample_size=0.5}/loss_logistic-decomposable/dataset_emotions/models/model.pickle"...
Writing output data to file "python/tests/res/tmp/instance-sampling_with-replacement{sample_size=0.5}/loss_logistic-decomposable/dataset_emotions/results/rules.txt"...
Writing output data to file "python/tests/res/tmp/instance-sampling_with-replacement{sample_size=0.5}/loss_logistic-decomposable/dataset_emotions/results/model_characteristics.csv"...
Successfully finished experiment after <duration>

Running experiment (4 / 8): "mlrl-testbed mlrl.boosting --base-dir python/tests/res/tmp --data-dir python/tests/res/data --dataset emotions --feature-format sparse --instance-sampling with-replacement{sample_size=0.5} --log-level debug --loss logistic-decomposable --model-save-dir instance-sampling_with-replacement{sample_size=0.5}/loss_logistic-decomposable/feature-format_sparse/dataset_emotions/models --parameter-save-dir instance-sampling_with-replacement{sample_size=0.5}/loss_logistic-decomposable/feature-format_sparse/dataset_emotions/parameters --result-dir instance-sampling_with-replacement{sample_size=0.5}/loss_logistic-decomposable/feature-format_sparse/dataset_emotions/results --save-all true --save-evaluation true --save-meta-data false"
Starting experiment using the classification algorithm "BoomerClassifier"...
Using separate training and test sets...
Reading input data from file "python/tests/res/data/emotions.arff"...
Parsing meta-data from file "python/tests/res/data/emotions.xml"...
Writing output data to file "python/tests/res/tmp/instance-sampling_with-replacement{sample_size=0.5}/loss_logistic-decomposable/feature-format_sparse/dataset_emotions/results/data_characteristics.csv"...
Writing output data to file "python/tests/res/tmp/instance-sampling_with-replacement{sample_size=0.5}/loss_logistic-decomposable/feature-format_sparse/dataset_emotions/parameters/parameters.csv"...
Fitting model to 397 training examples...
A sparse matrix with sparse value 0.0 is used to store the feature values of the training examples
A dense matrix is used to store the labels of the training examples
Successfully fit model in <duration>
Predicting for 196 test examples...
A sparse matrix with sparse value 0.0 is used to store the feature values of the query examples
A dense matrix is used to store the predicted labels
Successfully predicted in <duration>
Evaluation result for test data:

Example-wise F1 (↑)         59.76
Example-wise Jaccard (↑)    51.62
Example-wise Precision (↑)  75.34
Example-wise Recall (↑)     60.88
Hamming Accuracy (↑)        80.02
Hamming Loss (↓)            19.98
Macro F1 (↑)                63.73
Macro Jaccard (↑)           47.81
Macro Precision (↑)         71.91
Macro Recall (↑)            59.21
Micro F1 (↑)                65.79
Micro Jaccard (↑)           49.02
Micro Precision (↑)         72.44
Micro Recall (↑)            60.27
Subset 0/1 Loss (↓)         74.49
Subset Accuracy (↑)         25.51

Writing output data to file "python/tests/res/tmp/instance-sampling_with-replacement{sample_size=0.5}/loss_logistic-decomposable/feature-format_sparse/dataset_emotions/results/evaluation_test.csv"...
Writing output data to file "python/tests/res/tmp/instance-sampling_with-replacement{sample_size=0.5}/loss_logistic-decomposable/feature-format_sparse/dataset_emotions/results/ground_truth_test.arff"...
Writing output data to file "python/tests/res/tmp/instance-sampling_with-replacement{sample_size=0.5}/loss_logistic-decomposable/feature-format_sparse/dataset_emotions/results/prediction_characteristics_test.csv"...
Writing output data to file "python/tests/res/tmp/instance-sampling_with-replacement{sample_size=0.5}/loss_logistic-decomposable/feature-format_sparse/dataset_emotions/results/predictions_test.arff"...
Writing output data to file "python/tests/res/tmp/instance-sampling_with-replacement{sample_size=0.5}/loss_logistic-decomposable/feature-format_sparse/dataset_emotions/results/joint_probability_calibration_model.csv"...
Writing output data to file "python/tests/res/tmp/instance-sampling_with-replacement{sample_size=0.5}/loss_logistic-decomposable/feature-format_sparse/dataset_emotions/results/label_vectors.csv"...
Writing output data to file "python/tests/res/tmp/instance-sampling_with-replacement{sample_size=0.5}/loss_logistic-decomposable/feature-format_sparse/dataset_emotions/results/marginal_probability_calibration_model.csv"...
Writing output data to file "python/tests/res/tmp/instance-sampling_with-replacement{sample_size=0.5}/loss_logistic-decomposable/feature-format_sparse/dataset_emotions/models/model.pickle"...
Writing output data to file "python/tests/res/tmp/instance-sampling_with-replacement{sample_size=0.5}/loss_logistic-decomposable/feature-format_sparse/dataset_emotions/results/rules.txt"...
Writing output data to file "python/tests/res/tmp/instance-sampling_with-replacement{sample_size=0.5}/loss_logistic-decomposable/feature-format_sparse/dataset_emotions/results/model_characteristics.csv"...
Successfully finished experiment after <duration>

Running experiment (5 / 8): "mlrl-testbed mlrl.boosting --base-dir python/tests/res/tmp --data-dir python/tests/res/data --dataset enron --instance-sampling none --log-level debug --loss logistic-decomposable --model-save-dir instance-sampling_none/loss_logistic-decomposable/dataset_enron/models --parameter-save-dir instance-sampling_none/loss_logistic-decomposable/dataset_enron/parameters --result-dir instance-sampling_none/loss_logistic-decomposable/dataset_enron/results --save-all true --save-evaluation true --save-meta-data false"
Starting experiment using the classification algorithm "BoomerClassifier"...
Using separate training and test sets...
Reading input data from file "python/tests/res/data/enron.arff"...
Parsing meta-data from file "python/tests/res/data/enron.xml"...
Writing output data to file "python/tests/res/tmp/instance-sampling_none/loss_logistic-decomposable/dataset_enron/results/data_characteristics.csv"...
Writing output data to file "python/tests/res/tmp/instance-sampling_none/loss_logistic-decomposable/dataset_enron/parameters/parameters.csv"...
Fitting model to 1140 training examples...
A sparse matrix with sparse value 0.0 is used to store the feature values of the training examples
A sparse matrix is used to store the labels of the training examples
Successfully fit model in <duration>
Predicting for 562 test examples...
A sparse matrix with sparse value 0.0 is used to store the feature values of the query examples
A sparse matrix is used to store the predicted labels
Successfully predicted in <duration>
Evaluation result for test data:

Example-wise F1 (↑)         57.44
Example-wise Jaccard (↑)    46.65
Example-wise Precision (↑)  75.41
Example-wise Recall (↑)     53.46
Hamming Accuracy (↑)        95.54
Hamming Loss (↓)             4.46
Macro F1 (↑)                22.37
Macro Jaccard (↑)           16.81
Macro Precision (↑)         61.04
Macro Recall (↑)            18.92
Micro F1 (↑)                58.78
Micro Jaccard (↑)           41.63
Micro Precision (↑)         71.2
Micro Recall (↑)            50.05
Subset 0/1 Loss (↓)         84.88
Subset Accuracy (↑)         15.12

Writing output data to file "python/tests/res/tmp/instance-sampling_none/loss_logistic-decomposable/dataset_enron/results/evaluation_test.csv"...
Writing output data to file "python/tests/res/tmp/instance-sampling_none/loss_logistic-decomposable/dataset_enron/results/ground_truth_test.arff"...
Writing output data to file "python/tests/res/tmp/instance-sampling_none/loss_logistic-decomposable/dataset_enron/results/prediction_characteristics_test.csv"...
Writing output data to file "python/tests/res/tmp/instance-sampling_none/loss_logistic-decomposable/dataset_enron/results/predictions_test.arff"...
Writing output data to file "python/tests/res/tmp/instance-sampling_none/loss_logistic-decomposable/dataset_enron/results/joint_probability_calibration_model.csv"...
Writing output data to file "python/tests/res/tmp/instance-sampling_none/loss_logistic-decomposable/dataset_enron/results/label_vectors.csv"...
Writing output data to file "python/tests/res/tmp/instance-sampling_none/loss_logistic-decomposable/dataset_enron/results/marginal_probability_calibration_model.csv"...
Writing output data to file "python/tests/res/tmp/instance-sampling_none/loss_logistic-decomposable/dataset_enron/models/model.pickle"...
Writing output data to file "python/tests/res/tmp/instance-sampling_none/loss_logistic-decomposable/dataset_enron/results/rules.txt"...
Writing output data to file "python/tests/res/tmp/instance-sampling_none/loss_logistic-decomposable/dataset_enron/results/model_characteristics.csv"...
Successfully finished experiment after <duration>

Running experiment (6 / 8): "mlrl-testbed mlrl.boosting --base-dir python/tests/res/tmp --data-dir python/tests/res/data --dataset enron --feature-format sparse --instance-sampling none --log-level debug --loss logistic-decomposable --model-save-dir instance-sampling_none/loss_logistic-decomposable/feature-format_sparse/dataset_enron/models --parameter-save-dir instance-sampling_none/loss_logistic-decomposable/feature-format_sparse/dataset_enron/parameters --result-dir instance-sampling_none/loss_logistic-decomposable/feature-format_sparse/dataset_enron/results --save-all true --save-evaluation true --save-meta-data false"
Starting experiment using the classification algorithm "BoomerClassifier"...
Using separate training and test sets...
Reading input data from file "python/tests/res/data/enron.arff"...
Parsing meta-data from file "python/tests/res/data/enron.xml"...
Writing output data to file "python/tests/res/tmp/instance-sampling_none/loss_logistic-decomposable/feature-format_sparse/dataset_enron/results/data_characteristics.csv"...
Writing output data to file "python/tests/res/tmp/instance-sampling_none/loss_logistic-decomposable/feature-format_sparse/dataset_enron/parameters/parameters.csv"...
Fitting model to 1140 training examples...
A sparse matrix with sparse value 0.0 is used to store the feature values of the training examples
A sparse matrix is used to store the labels of the training examples
Successfully fit model in <duration>
Predicting for 562 test examples...
A sparse matrix with sparse value 0.0 is used to store the feature values of the query examples
A sparse matrix is used to store the predicted labels
Successfully predicted in <duration>
Evaluation result for test data:

Example-wise F1 (↑)         57.44
Example-wise Jaccard (↑)    46.65
Example-wise Precision (↑)  75.41
Example-wise Recall (↑)     53.46
Hamming Accuracy (↑)        95.54
Hamming Loss (↓)             4.46
Macro F1 (↑)                22.37
Macro Jaccard (↑)           16.81
Macro Precision (↑)         61.04
Macro Recall (↑)            18.92
Micro F1 (↑)                58.78
Micro Jaccard (↑)           41.63
Micro Precision (↑)         71.2
Micro Recall (↑)            50.05
Subset 0/1 Loss (↓)         84.88
Subset Accuracy (↑)         15.12

Writing output data to file "python/tests/res/tmp/instance-sampling_none/loss_logistic-decomposable/feature-format_sparse/dataset_enron/results/evaluation_test.csv"...
Writing output data to file "python/tests/res/tmp/instance-sampling_none/loss_logistic-decomposable/feature-format_sparse/dataset_enron/results/ground_truth_test.arff"...
Writing output data to file "python/tests/res/tmp/instance-sampling_none/loss_logistic-decomposable/feature-format_sparse/dataset_enron/results/prediction_characteristics_test.csv"...
Writing output data to file "python/tests/res/tmp/instance-sampling_none/loss_logistic-decomposable/feature-format_sparse/dataset_enron/results/predictions_test.arff"...
Writing output data to file "python/tests/res/tmp/instance-sampling_none/loss_logistic-decomposable/feature-format_sparse/dataset_enron/results/joint_probability_calibration_model.csv"...
Writing output data to file "python/tests/res/tmp/instance-sampling_none/loss_logistic-decomposable/feature-format_sparse/dataset_enron/results/label_vectors.csv"...
Writing output data to file "python/tests/res/tmp/instance-sampling_none/loss_logistic-decomposable/feature-format_sparse/dataset_enron/results/marginal_probability_calibration_model.csv"...
Writing output data to file "python/tests/res/tmp/instance-sampling_none/loss_logistic-decomposable/feature-format_sparse/dataset_enron/models/model.pickle"...
Writing output data to file "python/tests/res/tmp/instance-sampling_none/loss_logistic-decomposable/feature-format_sparse/dataset_enron/results/rules.txt"...
Writing output data to file "python/tests/res/tmp/instance-sampling_none/loss_logistic-decomposable/feature-format_sparse/dataset_enron/results/model_characteristics.csv"...
Successfully finished experiment after <duration>

Running experiment (7 / 8): "mlrl-testbed mlrl.boosting --base-dir python/tests/res/tmp --data-dir python/tests/res/data --dataset enron --instance-sampling with-replacement{sample_size=0.5} --log-level debug --loss logistic-decomposable --model-save-dir instance-sampling_with-replacement{sample_size=0.5}/loss_logistic-decomposable/dataset_enron/models --parameter-save-dir instance-sampling_with-replacement{sample_size=0.5}/loss_logistic-decomposable/dataset_enron/parameters --result-dir instance-sampling_with-replacement{sample_size=0.5}/loss_logistic-decomposable/dataset_enron/results --save-all true --save-evaluation true --save-meta-data false"
Starting experiment using the classification algorithm "BoomerClassifier"...
Using separate training and test sets...
Reading input data from file "python/tests/res/data/enron.arff"...
Parsing meta-data from file "python/tests/res/data/enron.xml"...
Writing output data to file "python/tests/res/tmp/instance-sampling_with-replacement{sample_size=0.5}/loss_logistic-decomposable/dataset_enron/results/data_characteristics.csv"...
Writing output data to file "python/tests/res/tmp/instance-sampling_with-replacement{sample_size=0.5}/loss_logistic-decomposable/dataset_enron/parameters/parameters.csv"...
Fitting model to 1140 training examples...
A sparse matrix with sparse value 0.0 is used to store the feature values of the training examples
A sparse matrix is used to store the labels of the training examples
Successfully fit model in <duration>
Predicting for 562 test examples...
A sparse matrix with sparse value 0.0 is used to store the feature values of the query examples
A sparse matrix is used to store the predicted labels
Successfully predicted in <duration>
Evaluation result for test data:

Example-wise F1 (↑)         57.25
Example-wise Jaccard (↑)    46.42
Example-wise Precision (↑)  75.97
Example-wise Recall (↑)     52.86
Hamming Accuracy (↑)        95.62
Hamming Loss (↓)             4.38
Macro F1 (↑)                21.28
Macro Jaccard (↑)           16.17
Macro Precision (↑)         62.29
Macro Recall (↑)            18.08
Micro F1 (↑)                59.02
Micro Jaccard (↑)           41.86
Micro Precision (↑)         72.79
Micro Recall (↑)            49.63
Subset 0/1 Loss (↓)         85.59
Subset Accuracy (↑)         14.41

Writing output data to file "python/tests/res/tmp/instance-sampling_with-replacement{sample_size=0.5}/loss_logistic-decomposable/dataset_enron/results/evaluation_test.csv"...
Writing output data to file "python/tests/res/tmp/instance-sampling_with-replacement{sample_size=0.5}/loss_logistic-decomposable/dataset_enron/results/ground_truth_test.arff"...
Writing output data to file "python/tests/res/tmp/instance-sampling_with-replacement{sample_size=0.5}/loss_logistic-decomposable/dataset_enron/results/prediction_characteristics_test.csv"...
Writing output data to file "python/tests/res/tmp/instance-sampling_with-replacement{sample_size=0.5}/loss_logistic-decomposable/dataset_enron/results/predictions_test.arff"...
Writing output data to file "python/tests/res/tmp/instance-sampling_with-replacement{sample_size=0.5}/loss_logistic-decomposable/dataset_enron/results/joint_probability_calibration_model.csv"...
Writing output data to file "python/tests/res/tmp/instance-sampling_with-replacement{sample_size=0.5}/loss_logistic-decomposable/dataset_enron/results/label_vectors.csv"...
Writing output data to file "python/tests/res/tmp/instance-sampling_with-replacement{sample_size=0.5}/loss_logistic-decomposable/dataset_enron/results/marginal_probability_calibration_model.csv"...
Writing output data to file "python/tests/res/tmp/instance-sampling_with-replacement{sample_size=0.5}/loss_logistic-decomposable/dataset_enron/models/model.pickle"...
Writing output data to file "python/tests/res/tmp/instance-sampling_with-replacement{sample_size=0.5}/loss_logistic-decomposable/dataset_enron/results/rules.txt"...
Writing output data to file "python/tests/res/tmp/instance-sampling_with-replacement{sample_size=0.5}/loss_logistic-decomposable/dataset_enron/results/model_characteristics.csv"...
Successfully finished experiment after <duration>

Running experiment (8 / 8): "mlrl-testbed mlrl.boosting --base-dir python/tests/res/tmp --data-dir python/tests/res/data --dataset enron --feature-format sparse --instance-sampling with-replacement{sample_size=0.5} --log-level debug --loss logistic-decomposable --model-save-dir instance-sampling_with-replacement{sample_size=0.5}/loss_logistic-decomposable/feature-format_sparse/dataset_enron/models --parameter-save-dir instance-sampling_with-replacement{sample_size=0.5}/loss_logistic-decomposable/feature-format_sparse/dataset_enron/parameters --result-dir instance-sampling_with-replacement{sample_size=0.5}/loss_logistic-decomposable/feature-format_sparse/dataset_enron/results --save-all true --save-evaluation true --save-meta-data false"
Starting experiment using the classification algorithm "BoomerClassifier"...
Using separate training and test sets...
Reading input data from file "python/tests/res/data/enron.arff"...
Parsing meta-data from file "python/tests/res/data/enron.xml"...
Writing output data to file "python/tests/res/tmp/instance-sampling_with-replacement{sample_size=0.5}/loss_logistic-decomposable/feature-format_sparse/dataset_enron/results/data_characteristics.csv"...
Writing output data to file "python/tests/res/tmp/instance-sampling_with-replacement{sample_size=0.5}/loss_logistic-decomposable/feature-format_sparse/dataset_enron/parameters/parameters.csv"...
Fitting model to 1140 training examples...
A sparse matrix with sparse value 0.0 is used to store the feature values of the training examples
A sparse matrix is used to store the labels of the training examples
Successfully fit model in <duration>
Predicting for 562 test examples...
A sparse matrix with sparse value 0.0 is used to store the feature values of the query examples
A sparse matrix is used to store the predicted labels
Successfully predicted in <duration>
Evaluation result for test data:

Example-wise F1 (↑)         57.25
Example-wise Jaccard (↑)    46.42
Example-wise Precision (↑)  75.97
Example-wise Recall (↑)     52.86
Hamming Accuracy (↑)        95.62
Hamming Loss (↓)             4.38
Macro F1 (↑)                21.28
Macro Jaccard (↑)           16.17
Macro Precision (↑)         62.29
Macro Recall (↑)            18.08
Micro F1 (↑)                59.02
Micro Jaccard (↑)           41.86
Micro Precision (↑)         72.79
Micro Recall (↑)            49.63
Subset 0/1 Loss (↓)         85.59
Subset Accuracy (↑)         14.41

Writing output data to file "python/tests/res/tmp/instance-sampling_with-replacement{sample_size=0.5}/loss_logistic-decomposable/feature-format_sparse/dataset_enron/results/evaluation_test.csv"...
Writing output data to file "python/tests/res/tmp/instance-sampling_with-replacement{sample_size=0.5}/loss_logistic-decomposable/feature-format_sparse/dataset_enron/results/ground_truth_test.arff"...
Writing output data to file "python/tests/res/tmp/instance-sampling_with-replacement{sample_size=0.5}/loss_logistic-decomposable/feature-format_sparse/dataset_enron/results/prediction_characteristics_test.csv"...
Writing output data to file "python/tests/res/tmp/instance-sampling_with-replacement{sample_size=0.5}/loss_logistic-decomposable/feature-format_sparse/dataset_enron/results/predictions_test.arff"...
Writing output data to file "python/tests/res/tmp/instance-sampling_with-replacement{sample_size=0.5}/loss_logistic-decomposable/feature-format_sparse/dataset_enron/results/joint_probability_calibration_model.csv"...
Writing output data to file "python/tests/res/tmp/instance-sampling_with-replacement{sample_size=0.5}/loss_logistic-decomposable/feature-format_sparse/dataset_enron/results/label_vectors.csv"...
Writing output data to file "python/tests/res/tmp/instance-sampling_with-replacement{sample_size=0.5}/loss_logistic-decomposable/feature-format_sparse/dataset_enron/results/marginal_probability_calibration_model.csv"...
Writing output data to file "python/tests/res/tmp/instance-sampling_with-replacement{sample_size=0.5}/loss_logistic-decomposable/feature-format_sparse/dataset_enron/models/model.pickle"...
Writing output data to file "python/tests/res/tmp/instance-sampling_with-replacement{sample_size=0.5}/loss_logistic-decomposable/feature-format_sparse/dataset_enron/results/rules.txt"...
Writing output data to file "python/tests/res/tmp/instance-sampling_with-replacement{sample_size=0.5}/loss_logistic-decomposable/feature-format_sparse/dataset_enron/results/model_characteristics.csv"...
Successfully finished experiment after <duration>
Successfully finished 8 experiments after <duration>
