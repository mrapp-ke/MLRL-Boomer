mlrl-testbed mlrl.boosting --log-level debug --base-dir python/tests/res/tmp --data-dir python/tests/res/data --dataset emotions --result-dir results --save-evaluation true --incremental-evaluation true{step_size=50} --print-evaluation true --save-evaluation true
Checking if output files do already exist...
Starting experiment using the classification algorithm "BoomerClassifier"...
Writing output data to file "python/tests/res/tmp/metadata.yml"...
Using separate training and test sets...
Reading input data from file "python/tests/res/data/emotions.arff"...
Parsing meta-data from file "python/tests/res/data/emotions.xml"...
Fitting model to 397 training examples...
A dense matrix is used to store the feature values of the training examples
A dense matrix is used to store the labels of the training examples
Successfully fit model in <duration>
A dense matrix is used to store the feature values of the query examples
A dense matrix is used to store the predicted labels
Predicting for 196 test examples using a model of size 50...
Successfully predicted in <duration>
Evaluation result for test data using a model of size 50:

Example-wise F1 (↑)         57.45
Example-wise Jaccard (↑)    50.04
Example-wise Precision (↑)  81.38
Example-wise Recall (↑)     56.38
Hamming Accuracy (↑)        80.7
Hamming Loss (↓)            19.3
Macro F1 (↑)                61.38
Macro Jaccard (↑)           45.8
Macro Precision (↑)         77.93
Macro Recall (↑)            53.81
Micro F1 (↑)                64.91
Micro Jaccard (↑)           48.05
Micro Precision (↑)         77.21
Micro Recall (↑)            56
Subset 0/1 Loss (↓)         72.45
Subset Accuracy (↑)         27.55

Writing output data to file "python/tests/res/tmp/results/evaluation_test.csv"...
Predicting for 196 test examples using a model of size 100...
Successfully predicted in <duration>
Evaluation result for test data using a model of size 100:

Example-wise F1 (↑)         59.35
Example-wise Jaccard (↑)    51.45
Example-wise Precision (↑)  78.57
Example-wise Recall (↑)     58.59
Hamming Accuracy (↑)        80.36
Hamming Loss (↓)            19.64
Macro F1 (↑)                61.8
Macro Jaccard (↑)           46.17
Macro Precision (↑)         77.13
Macro Recall (↑)            55.41
Micro F1 (↑)                65.05
Micro Jaccard (↑)           48.21
Micro Precision (↑)         75.17
Micro Recall (↑)            57.33
Subset 0/1 Loss (↓)         73.47
Subset Accuracy (↑)         26.53

Writing output data to file "python/tests/res/tmp/results/evaluation_test.csv"...
Predicting for 196 test examples using a model of size 150...
Successfully predicted in <duration>
Evaluation result for test data using a model of size 150:

Example-wise F1 (↑)         61.02
Example-wise Jaccard (↑)    53.66
Example-wise Precision (↑)  77.98
Example-wise Recall (↑)     60.71
Hamming Accuracy (↑)        81.21
Hamming Loss (↓)            18.79
Macro F1 (↑)                65.46
Macro Jaccard (↑)           49.42
Macro Precision (↑)         77.52
Macro Recall (↑)            59.19
Micro F1 (↑)                67.16
Micro Jaccard (↑)           50.56
Micro Precision (↑)         75.84
Micro Recall (↑)            60.27
Subset 0/1 Loss (↓)         70.41
Subset Accuracy (↑)         29.59

Writing output data to file "python/tests/res/tmp/results/evaluation_test.csv"...
Predicting for 196 test examples using a model of size 200...
Successfully predicted in <duration>
Evaluation result for test data using a model of size 200:

Example-wise F1 (↑)         61
Example-wise Jaccard (↑)    53.57
Example-wise Precision (↑)  77.47
Example-wise Recall (↑)     60.29
Hamming Accuracy (↑)        81.12
Hamming Loss (↓)            18.88
Macro F1 (↑)                64.86
Macro Jaccard (↑)           48.77
Macro Precision (↑)         77.74
Macro Recall (↑)            58.36
Micro F1 (↑)                66.87
Micro Jaccard (↑)           50.22
Micro Precision (↑)         75.93
Micro Recall (↑)            59.73
Subset 0/1 Loss (↓)         69.9
Subset Accuracy (↑)         30.1

Writing output data to file "python/tests/res/tmp/results/evaluation_test.csv"...
Predicting for 196 test examples using a model of size 250...
Successfully predicted in <duration>
Evaluation result for test data using a model of size 250:

Example-wise F1 (↑)         61.75
Example-wise Jaccard (↑)    54.17
Example-wise Precision (↑)  78.15
Example-wise Recall (↑)     61.05
Hamming Accuracy (↑)        81.46
Hamming Loss (↓)            18.54
Macro F1 (↑)                65.45
Macro Jaccard (↑)           49.44
Macro Precision (↑)         77.9
Macro Recall (↑)            59.16
Micro F1 (↑)                67.56
Micro Jaccard (↑)           51.01
Micro Precision (↑)         76.43
Micro Recall (↑)            60.53
Subset 0/1 Loss (↓)         69.9
Subset Accuracy (↑)         30.1

Writing output data to file "python/tests/res/tmp/results/evaluation_test.csv"...
Predicting for 196 test examples using a model of size 300...
Successfully predicted in <duration>
Evaluation result for test data using a model of size 300:

Example-wise F1 (↑)         61.75
Example-wise Jaccard (↑)    53.7
Example-wise Precision (↑)  78.4
Example-wise Recall (↑)     61.48
Hamming Accuracy (↑)        81.38
Hamming Loss (↓)            18.62
Macro F1 (↑)                65.71
Macro Jaccard (↑)           49.72
Macro Precision (↑)         77.21
Macro Recall (↑)            59.78
Micro F1 (↑)                67.65
Micro Jaccard (↑)           51.12
Micro Precision (↑)         75.83
Micro Recall (↑)            61.07
Subset 0/1 Loss (↓)         71.94
Subset Accuracy (↑)         28.06

Writing output data to file "python/tests/res/tmp/results/evaluation_test.csv"...
Predicting for 196 test examples using a model of size 350...
Successfully predicted in <duration>
Evaluation result for test data using a model of size 350:

Example-wise F1 (↑)         62.86
Example-wise Jaccard (↑)    54.97
Example-wise Precision (↑)  79
Example-wise Recall (↑)     61.82
Hamming Accuracy (↑)        81.63
Hamming Loss (↓)            18.37
Macro F1 (↑)                66.41
Macro Jaccard (↑)           50.42
Macro Precision (↑)         78.28
Macro Recall (↑)            60.44
Micro F1 (↑)                68.05
Micro Jaccard (↑)           51.57
Micro Precision (↑)         76.41
Micro Recall (↑)            61.33
Subset 0/1 Loss (↓)         70.41
Subset Accuracy (↑)         29.59

Writing output data to file "python/tests/res/tmp/results/evaluation_test.csv"...
Predicting for 196 test examples using a model of size 400...
Successfully predicted in <duration>
Evaluation result for test data using a model of size 400:

Example-wise F1 (↑)         63.57
Example-wise Jaccard (↑)    56.25
Example-wise Precision (↑)  78.49
Example-wise Recall (↑)     63.27
Hamming Accuracy (↑)        82.06
Hamming Loss (↓)            17.94
Macro F1 (↑)                67.12
Macro Jaccard (↑)           51.36
Macro Precision (↑)         77.63
Macro Recall (↑)            61.61
Micro F1 (↑)                69.02
Micro Jaccard (↑)           52.69
Micro Precision (↑)         76.8
Micro Recall (↑)            62.67
Subset 0/1 Loss (↓)         67.86
Subset Accuracy (↑)         32.14

Writing output data to file "python/tests/res/tmp/results/evaluation_test.csv"...
Predicting for 196 test examples using a model of size 450...
Successfully predicted in <duration>
Evaluation result for test data using a model of size 450:

Example-wise F1 (↑)         61.87
Example-wise Jaccard (↑)    54.34
Example-wise Precision (↑)  77.89
Example-wise Recall (↑)     61.56
Hamming Accuracy (↑)        81.29
Hamming Loss (↓)            18.71
Macro F1 (↑)                65.13
Macro Jaccard (↑)           49.56
Macro Precision (↑)         75.9
Macro Recall (↑)            59.92
Micro F1 (↑)                67.55
Micro Jaccard (↑)           51
Micro Precision (↑)         75.58
Micro Recall (↑)            61.07
Subset 0/1 Loss (↓)         69.9
Subset Accuracy (↑)         30.1

Writing output data to file "python/tests/res/tmp/results/evaluation_test.csv"...
Predicting for 196 test examples using a model of size 500...
Successfully predicted in <duration>
Evaluation result for test data using a model of size 500:

Example-wise F1 (↑)         62.65
Example-wise Jaccard (↑)    54.63
Example-wise Precision (↑)  77.72
Example-wise Recall (↑)     62.33
Hamming Accuracy (↑)        81.38
Hamming Loss (↓)            18.62
Macro F1 (↑)                65.53
Macro Jaccard (↑)           49.9
Macro Precision (↑)         75.61
Macro Recall (↑)            60.56
Micro F1 (↑)                67.94
Micro Jaccard (↑)           51.44
Micro Precision (↑)         75.32
Micro Recall (↑)            61.87
Subset 0/1 Loss (↓)         70.92
Subset Accuracy (↑)         29.08

Writing output data to file "python/tests/res/tmp/results/evaluation_test.csv"...
Predicting for 196 test examples using a model of size 550...
Successfully predicted in <duration>
Evaluation result for test data using a model of size 550:

Example-wise F1 (↑)         62.72
Example-wise Jaccard (↑)    54.55
Example-wise Precision (↑)  77.72
Example-wise Recall (↑)     62.41
Hamming Accuracy (↑)        81.29
Hamming Loss (↓)            18.71
Macro F1 (↑)                65.54
Macro Jaccard (↑)           49.82
Macro Precision (↑)         75.78
Macro Recall (↑)            60.57
Micro F1 (↑)                67.84
Micro Jaccard (↑)           51.33
Micro Precision (↑)         75.08
Micro Recall (↑)            61.87
Subset 0/1 Loss (↓)         71.43
Subset Accuracy (↑)         28.57

Writing output data to file "python/tests/res/tmp/results/evaluation_test.csv"...
Predicting for 196 test examples using a model of size 600...
Successfully predicted in <duration>
Evaluation result for test data using a model of size 600:

Example-wise F1 (↑)         62.96
Example-wise Jaccard (↑)    54.97
Example-wise Precision (↑)  77.38
Example-wise Recall (↑)     62.5
Hamming Accuracy (↑)        81.12
Hamming Loss (↓)            18.88
Macro F1 (↑)                64.75
Macro Jaccard (↑)           49.17
Macro Precision (↑)         75.15
Macro Recall (↑)            60.12
Micro F1 (↑)                67.54
Micro Jaccard (↑)           50.99
Micro Precision (↑)         74.76
Micro Recall (↑)            61.6
Subset 0/1 Loss (↓)         69.9
Subset Accuracy (↑)         30.1

Writing output data to file "python/tests/res/tmp/results/evaluation_test.csv"...
Predicting for 196 test examples using a model of size 650...
Successfully predicted in <duration>
Evaluation result for test data using a model of size 650:

Example-wise F1 (↑)         62.69
Example-wise Jaccard (↑)    54.55
Example-wise Precision (↑)  77.72
Example-wise Recall (↑)     62.76
Hamming Accuracy (↑)        81.29
Hamming Loss (↓)            18.71
Macro F1 (↑)                65.26
Macro Jaccard (↑)           49.64
Macro Precision (↑)         75.83
Macro Recall (↑)            60.52
Micro F1 (↑)                67.84
Micro Jaccard (↑)           51.33
Micro Precision (↑)         75.08
Micro Recall (↑)            61.87
Subset 0/1 Loss (↓)         70.92
Subset Accuracy (↑)         29.08

Writing output data to file "python/tests/res/tmp/results/evaluation_test.csv"...
Predicting for 196 test examples using a model of size 700...
Successfully predicted in <duration>
Evaluation result for test data using a model of size 700:

Example-wise F1 (↑)         62.77
Example-wise Jaccard (↑)    54.63
Example-wise Precision (↑)  77.64
Example-wise Recall (↑)     62.76
Hamming Accuracy (↑)        81.12
Hamming Loss (↓)            18.88
Macro F1 (↑)                65.15
Macro Jaccard (↑)           49.48
Macro Precision (↑)         75.38
Macro Recall (↑)            60.53
Micro F1 (↑)                67.64
Micro Jaccard (↑)           51.1
Micro Precision (↑)         74.6
Micro Recall (↑)            61.87
Subset 0/1 Loss (↓)         70.92
Subset Accuracy (↑)         29.08

Writing output data to file "python/tests/res/tmp/results/evaluation_test.csv"...
Predicting for 196 test examples using a model of size 750...
Successfully predicted in <duration>
Evaluation result for test data using a model of size 750:

Example-wise F1 (↑)         63.11
Example-wise Jaccard (↑)    55.14
Example-wise Precision (↑)  78.91
Example-wise Recall (↑)     62.67
Hamming Accuracy (↑)        81.46
Hamming Loss (↓)            18.54
Macro F1 (↑)                65.4
Macro Jaccard (↑)           49.87
Macro Precision (↑)         76.21
Macro Recall (↑)            60.55
Micro F1 (↑)                68.04
Micro Jaccard (↑)           51.56
Micro Precision (↑)         75.57
Micro Recall (↑)            61.87
Subset 0/1 Loss (↓)         69.9
Subset Accuracy (↑)         30.1

Writing output data to file "python/tests/res/tmp/results/evaluation_test.csv"...
Predicting for 196 test examples using a model of size 800...
Successfully predicted in <duration>
Evaluation result for test data using a model of size 800:

Example-wise F1 (↑)         62.67
Example-wise Jaccard (↑)    54.89
Example-wise Precision (↑)  78.4
Example-wise Recall (↑)     62.41
Hamming Accuracy (↑)        81.29
Hamming Loss (↓)            18.71
Macro F1 (↑)                65.01
Macro Jaccard (↑)           49.46
Macro Precision (↑)         75.8
Macro Recall (↑)            60.15
Micro F1 (↑)                67.74
Micro Jaccard (↑)           51.22
Micro Precision (↑)         75.24
Micro Recall (↑)            61.6
Subset 0/1 Loss (↓)         69.9
Subset Accuracy (↑)         30.1

Writing output data to file "python/tests/res/tmp/results/evaluation_test.csv"...
Predicting for 196 test examples using a model of size 850...
Successfully predicted in <duration>
Evaluation result for test data using a model of size 850:

Example-wise F1 (↑)         62.67
Example-wise Jaccard (↑)    54.89
Example-wise Precision (↑)  78.4
Example-wise Recall (↑)     62.41
Hamming Accuracy (↑)        81.29
Hamming Loss (↓)            18.71
Macro F1 (↑)                64.99
Macro Jaccard (↑)           49.39
Macro Precision (↑)         75.84
Macro Recall (↑)            60.15
Micro F1 (↑)                67.74
Micro Jaccard (↑)           51.22
Micro Precision (↑)         75.24
Micro Recall (↑)            61.6
Subset 0/1 Loss (↓)         69.9
Subset Accuracy (↑)         30.1

Writing output data to file "python/tests/res/tmp/results/evaluation_test.csv"...
Predicting for 196 test examples using a model of size 900...
Successfully predicted in <duration>
Evaluation result for test data using a model of size 900:

Example-wise F1 (↑)         62.87
Example-wise Jaccard (↑)    55.06
Example-wise Precision (↑)  79.34
Example-wise Recall (↑)     62.5
Hamming Accuracy (↑)        81.46
Hamming Loss (↓)            18.54
Macro F1 (↑)                65.44
Macro Jaccard (↑)           49.72
Macro Precision (↑)         77
Macro Recall (↑)            60.28
Micro F1 (↑)                67.94
Micro Jaccard (↑)           51.45
Micro Precision (↑)         75.74
Micro Recall (↑)            61.6
Subset 0/1 Loss (↓)         69.39
Subset Accuracy (↑)         30.61

Writing output data to file "python/tests/res/tmp/results/evaluation_test.csv"...
Predicting for 196 test examples using a model of size 950...
Successfully predicted in <duration>
Evaluation result for test data using a model of size 950:

Example-wise F1 (↑)         62.93
Example-wise Jaccard (↑)    55.23
Example-wise Precision (↑)  78.66
Example-wise Recall (↑)     62.67
Hamming Accuracy (↑)        81.38
Hamming Loss (↓)            18.62
Macro F1 (↑)                65.36
Macro Jaccard (↑)           49.66
Macro Precision (↑)         76.1
Macro Recall (↑)            60.46
Micro F1 (↑)                67.94
Micro Jaccard (↑)           51.44
Micro Precision (↑)         75.32
Micro Recall (↑)            61.87
Subset 0/1 Loss (↓)         69.39
Subset Accuracy (↑)         30.61

Writing output data to file "python/tests/res/tmp/results/evaluation_test.csv"...
Predicting for 196 test examples using a model of size 1000...
Successfully predicted in <duration>
Evaluation result for test data using a model of size 1000:

Example-wise F1 (↑)         62.77
Example-wise Jaccard (↑)    55.06
Example-wise Precision (↑)  78.06
Example-wise Recall (↑)     62.41
Hamming Accuracy (↑)        81.21
Hamming Loss (↓)            18.79
Macro F1 (↑)                64.89
Macro Jaccard (↑)           49.26
Macro Precision (↑)         75.68
Macro Recall (↑)            60.15
Micro F1 (↑)                67.64
Micro Jaccard (↑)           51.11
Micro Precision (↑)         75
Micro Recall (↑)            61.6
Subset 0/1 Loss (↓)         69.39
Subset Accuracy (↑)         30.61

Writing output data to file "python/tests/res/tmp/results/evaluation_test.csv"...
Successfully finished experiment after <duration>
