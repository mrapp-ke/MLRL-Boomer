mlrl-testbed mlrl.boosting --log-level debug --base-dir python/tests/res/tmp --data-dir python/tests/res/data --dataset langlog --result-dir results --save-evaluation true --statistic-format sparse --output-format dense --default-rule false --loss squared-hinge-decomposable --head-type single
Checking if output files do already exist...
Starting experiment using the classification algorithm "BoomerClassifier"...
Writing output data to file "python/tests/res/tmp/metadata.yml"...
Using separate training and test sets...
Reading input data from file "python/tests/res/data/langlog.arff"...
Parsing meta-data from file "python/tests/res/data/langlog.xml"...
Fitting model to 978 training examples...
A sparse matrix with sparse value 0.0 is used to store the feature values of the training examples
A dense matrix is used to store the labels of the training examples
Successfully fit model in <duration>
Predicting for 482 test examples...
A sparse matrix with sparse value 0.0 is used to store the feature values of the query examples
A sparse matrix is used to store the predicted labels
Successfully predicted in <duration>
Evaluation result for test data:

Example-wise F1 (↑)         21.58
Example-wise Jaccard (↑)    20.95
Example-wise Precision (↑)  93.36
Example-wise Recall (↑)     21.3
Hamming Accuracy (↑)        98.46
Hamming Loss (↓)             1.54
Macro F1 (↑)                10.25
Macro Jaccard (↑)            9.37
Macro Precision (↑)         90.8
Macro Recall (↑)             9.67
Micro F1 (↑)                12.87
Micro Jaccard (↑)            6.88
Micro Precision (↑)         54.67
Micro Recall (↑)             7.3
Subset 0/1 Loss (↓)         80.71
Subset Accuracy (↑)         19.29

Writing output data to file "python/tests/res/tmp/results/evaluation_test.csv"...
Successfully finished experiment after <duration>
