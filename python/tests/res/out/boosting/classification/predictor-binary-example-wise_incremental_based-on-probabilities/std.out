mlrl-testbed mlrl.boosting --log-level DEBUG --data-dir python/tests/res/data --dataset emotions --output-dir python/tests/res/tmp/results --marginal-probability-calibration isotonic --print-marginal-probability-calibration-model true --store-marginal-probability-calibration-model true --joint-probability-calibration isotonic --print-joint-probability-calibration-model true --store-joint-probability-calibration-model true --binary-predictor example-wise{based_on_probabilities=true} --incremental-evaluation true{step_size=50} --print-evaluation true --store-evaluation true --model-load-dir python/tests/res/tmp/models --model-save-dir python/tests/res/tmp/models
INFO Starting experiment using the classification algorithm "boomer"...
INFO Using separate training and test sets...
DEBUG Reading input data from file "python/tests/res/data/emotions.arff"...
DEBUG Parsing meta-data from file "python/tests/res/data/emotions.xml"...
DEBUG Reading input data from file "python/tests/res/tmp/models/model.pickle"...
INFO Successfully loaded model
DEBUG A dense matrix is used to store the feature values of the query examples
DEBUG A dense matrix is used to store the predicted labels
INFO Predicting for 196 test examples using a model of size 50...
INFO Successfully predicted in <duration>
INFO Evaluation result for test data using a model of size 50:

Example-wise F1         27.33
Example-wise Jaccard    21.98
Example-wise Precision  37.16
Example-wise Recall     23.13
Hamming Accuracy        64.2
Hamming Loss            35.8
Macro F1                20.61
Macro Jaccard           12.43
Macro Precision         68.36
Macro Recall            23.64
Micro F1                28.76
Micro Jaccard           16.8
Micro Precision         39.35
Micro Recall            22.67
Subset 0/1 Loss         93.88
Subset Accuracy          6.12

DEBUG Writing output data to file "python/tests/res/tmp/results/evaluation_test.csv"...
INFO Predicting for 196 test examples using a model of size 100...
INFO Successfully predicted in <duration>
INFO Evaluation result for test data using a model of size 100:

Example-wise F1         35.6
Example-wise Jaccard    29
Example-wise Precision  45.49
Example-wise Recall     32.06
Hamming Accuracy        67.69
Hamming Loss            32.31
Macro F1                34.88
Macro Jaccard           21.87
Macro Precision         66.35
Macro Recall            32.64
Micro F1                38.51
Micro Jaccard           23.85
Micro Precision         48.97
Micro Recall            31.73
Subset 0/1 Loss         90.31
Subset Accuracy          9.69

DEBUG Writing output data to file "python/tests/res/tmp/results/evaluation_test.csv"...
INFO Predicting for 196 test examples using a model of size 150...
INFO Successfully predicted in <duration>
INFO Evaluation result for test data using a model of size 150:

Example-wise F1         39.95
Example-wise Jaccard    32.71
Example-wise Precision  51.02
Example-wise Recall     35.97
Hamming Accuracy        69.39
Hamming Loss            30.61
Macro F1                38.65
Macro Jaccard           24.89
Macro Precision         62.8
Macro Recall            35.12
Micro F1                42.12
Micro Jaccard           26.68
Micro Precision         53.04
Micro Recall            34.93
Subset 0/1 Loss         88.78
Subset Accuracy         11.22

DEBUG Writing output data to file "python/tests/res/tmp/results/evaluation_test.csv"...
INFO Predicting for 196 test examples using a model of size 200...
INFO Successfully predicted in <duration>
INFO Evaluation result for test data using a model of size 200:

Example-wise F1         42.86
Example-wise Jaccard    35.39
Example-wise Precision  53.57
Example-wise Recall     39.2
Hamming Accuracy        70.58
Hamming Loss            29.42
Macro F1                42.98
Macro Jaccard           28.23
Macro Precision         64.98
Macro Recall            38.58
Micro F1                45.43
Micro Jaccard           29.39
Micro Precision         55.6
Micro Recall            38.4
Subset 0/1 Loss         86.73
Subset Accuracy         13.27

DEBUG Writing output data to file "python/tests/res/tmp/results/evaluation_test.csv"...
INFO Predicting for 196 test examples using a model of size 250...
INFO Successfully predicted in <duration>
INFO Evaluation result for test data using a model of size 250:

Example-wise F1         46.7
Example-wise Jaccard    38.45
Example-wise Precision  58.59
Example-wise Recall     42.77
Hamming Accuracy        71.77
Hamming Loss            28.23
Macro F1                45.81
Macro Jaccard           30.74
Macro Precision         60.98
Macro Recall            41.19
Micro F1                48.45
Micro Jaccard           31.97
Micro Precision         57.99
Micro Recall            41.6
Subset 0/1 Loss         86.22
Subset Accuracy         13.78

DEBUG Writing output data to file "python/tests/res/tmp/results/evaluation_test.csv"...
INFO Predicting for 196 test examples using a model of size 300...
INFO Successfully predicted in <duration>
INFO Evaluation result for test data using a model of size 300:

Example-wise F1         46.58
Example-wise Jaccard    37.94
Example-wise Precision  59.18
Example-wise Recall     42.18
Hamming Accuracy        71.43
Hamming Loss            28.57
Macro F1                45.06
Macro Jaccard           30.33
Macro Precision         56.63
Macro Recall            41
Micro F1                48.15
Micro Jaccard           31.71
Micro Precision         57.14
Micro Recall            41.6
Subset 0/1 Loss         87.76
Subset Accuracy         12.24

DEBUG Writing output data to file "python/tests/res/tmp/results/evaluation_test.csv"...
INFO Predicting for 196 test examples using a model of size 350...
INFO Successfully predicted in <duration>
INFO Evaluation result for test data using a model of size 350:

Example-wise F1         47.93
Example-wise Jaccard    39.18
Example-wise Precision  60.54
Example-wise Recall     43.71
Hamming Accuracy        71.85
Hamming Loss            28.15
Macro F1                46.74
Macro Jaccard           31.72
Macro Precision         56.3
Macro Recall            42.67
Micro F1                49.62
Micro Jaccard           33
Micro Precision         57.8
Micro Recall            43.47
Subset 0/1 Loss         87.24
Subset Accuracy         12.76

DEBUG Writing output data to file "python/tests/res/tmp/results/evaluation_test.csv"...
INFO Predicting for 196 test examples using a model of size 400...
INFO Successfully predicted in <duration>
INFO Evaluation result for test data using a model of size 400:

Example-wise F1         49.64
Example-wise Jaccard    40.96
Example-wise Precision  62.5
Example-wise Recall     44.64
Hamming Accuracy        72.79
Hamming Loss            27.21
Macro F1                48.64
Macro Jaccard           33.17
Macro Precision         58.57
Macro Recall            43.73
Micro F1                51.22
Micro Jaccard           34.43
Micro Precision         59.79
Micro Recall            44.8
Subset 0/1 Loss         85.2
Subset Accuracy         14.8

DEBUG Writing output data to file "python/tests/res/tmp/results/evaluation_test.csv"...
INFO Predicting for 196 test examples using a model of size 450...
INFO Successfully predicted in <duration>
INFO Evaluation result for test data using a model of size 450:

Example-wise F1         47.65
Example-wise Jaccard    39.05
Example-wise Precision  60.46
Example-wise Recall     42.86
Hamming Accuracy        71.77
Hamming Loss            28.23
Macro F1                46.94
Macro Jaccard           31.6
Macro Precision         56.43
Macro Recall            42.34
Micro F1                49.54
Micro Jaccard           32.93
Micro Precision         57.6
Micro Recall            43.47
Subset 0/1 Loss         87.24
Subset Accuracy         12.76

DEBUG Writing output data to file "python/tests/res/tmp/results/evaluation_test.csv"...
INFO Predicting for 196 test examples using a model of size 500...
INFO Successfully predicted in <duration>
INFO Evaluation result for test data using a model of size 500:

Example-wise F1         48.96
Example-wise Jaccard    40.58
Example-wise Precision  61.39
Example-wise Recall     44.39
Hamming Accuracy        71.94
Hamming Loss            28.06
Macro F1                47.77
Macro Jaccard           32.12
Macro Precision         57.18
Macro Recall            43.1
Micro F1                50.3
Micro Jaccard           33.6
Micro Precision         57.79
Micro Recall            44.53
Subset 0/1 Loss         84.69
Subset Accuracy         15.31

DEBUG Writing output data to file "python/tests/res/tmp/results/evaluation_test.csv"...
INFO Predicting for 196 test examples using a model of size 550...
INFO Successfully predicted in <duration>
INFO Evaluation result for test data using a model of size 550:

Example-wise F1         49.76
Example-wise Jaccard    41.15
Example-wise Precision  62.24
Example-wise Recall     44.98
Hamming Accuracy        72.19
Hamming Loss            27.81
Macro F1                47.75
Macro Jaccard           32.46
Macro Precision         56.03
Macro Recall            43.67
Micro F1                50.97
Micro Jaccard           34.21
Micro Precision         58.22
Micro Recall            45.33
Subset 0/1 Loss         84.69
Subset Accuracy         15.31

DEBUG Writing output data to file "python/tests/res/tmp/results/evaluation_test.csv"...
INFO Predicting for 196 test examples using a model of size 600...
INFO Successfully predicted in <duration>
INFO Evaluation result for test data using a model of size 600:

Example-wise F1         50.29
Example-wise Jaccard    41.74
Example-wise Precision  63.18
Example-wise Recall     45.24
Hamming Accuracy        72.45
Hamming Loss            27.55
Macro F1                48.42
Macro Jaccard           32.77
Macro Precision         57.73
Macro Recall            43.7
Micro F1                51.2
Micro Jaccard           34.41
Micro Precision         58.82
Micro Recall            45.33
Subset 0/1 Loss         84.18
Subset Accuracy         15.82

DEBUG Writing output data to file "python/tests/res/tmp/results/evaluation_test.csv"...
INFO Predicting for 196 test examples using a model of size 650...
INFO Successfully predicted in <duration>
INFO Evaluation result for test data using a model of size 650:

Example-wise F1         48.62
Example-wise Jaccard    40.09
Example-wise Precision  61.31
Example-wise Recall     43.71
Hamming Accuracy        71
Hamming Loss            29
Macro F1                46.63
Macro Jaccard           31.11
Macro Precision         55.14
Macro Recall            42.84
Micro F1                49.33
Micro Jaccard           32.74
Micro Precision         55.7
Micro Recall            44.27
Subset 0/1 Loss         85.71
Subset Accuracy         14.29

DEBUG Writing output data to file "python/tests/res/tmp/results/evaluation_test.csv"...
INFO Predicting for 196 test examples using a model of size 700...
INFO Successfully predicted in <duration>
INFO Evaluation result for test data using a model of size 700:

Example-wise F1         49.3
Example-wise Jaccard    40.85
Example-wise Precision  61.9
Example-wise Recall     44.3
Hamming Accuracy        70.83
Hamming Loss            29.17
Macro F1                46.69
Macro Jaccard           31.17
Macro Precision         54.49
Macro Recall            43.33
Micro F1                49.48
Micro Jaccard           32.88
Micro Precision         55.26
Micro Recall            44.8
Subset 0/1 Loss         84.69
Subset Accuracy         15.31

DEBUG Writing output data to file "python/tests/res/tmp/results/evaluation_test.csv"...
INFO Predicting for 196 test examples using a model of size 750...
INFO Successfully predicted in <duration>
INFO Evaluation result for test data using a model of size 750:

Example-wise F1         48.13
Example-wise Jaccard    39.23
Example-wise Precision  60.88
Example-wise Recall     43.54
Hamming Accuracy        70.15
Hamming Loss            29.85
Macro F1                45.63
Macro Jaccard           30.35
Macro Precision         52.39
Macro Recall            42.74
Micro F1                48.61
Micro Jaccard           32.11
Micro Precision         53.9
Micro Recall            44.27
Subset 0/1 Loss         87.24
Subset Accuracy         12.76

DEBUG Writing output data to file "python/tests/res/tmp/results/evaluation_test.csv"...
INFO Predicting for 196 test examples using a model of size 800...
INFO Successfully predicted in <duration>
INFO Evaluation result for test data using a model of size 800:

Example-wise F1         48.81
Example-wise Jaccard    40.17
Example-wise Precision  61.22
Example-wise Recall     44.22
Hamming Accuracy        70.32
Hamming Loss            29.68
Macro F1                46.13
Macro Jaccard           30.73
Macro Precision         53.18
Macro Recall            43.47
Micro F1                49.2
Micro Jaccard           32.63
Micro Precision         54.17
Micro Recall            45.07
Subset 0/1 Loss         85.71
Subset Accuracy         14.29

DEBUG Writing output data to file "python/tests/res/tmp/results/evaluation_test.csv"...
INFO Predicting for 196 test examples using a model of size 850...
INFO Successfully predicted in <duration>
INFO Evaluation result for test data using a model of size 850:

Example-wise F1         46.92
Example-wise Jaccard    38.45
Example-wise Precision  59.27
Example-wise Recall     42.26
Hamming Accuracy        69.05
Hamming Loss            30.95
Macro F1                44.12
Macro Jaccard           28.97
Macro Precision         51.41
Macro Recall            41.86
Micro F1                47.25
Micro Jaccard           30.93
Micro Precision         51.75
Micro Recall            43.47
Subset 0/1 Loss         87.24
Subset Accuracy         12.76

DEBUG Writing output data to file "python/tests/res/tmp/results/evaluation_test.csv"...
INFO Predicting for 196 test examples using a model of size 900...
INFO Successfully predicted in <duration>
INFO Evaluation result for test data using a model of size 900:

Example-wise F1         45.73
Example-wise Jaccard    37.43
Example-wise Precision  57.99
Example-wise Recall     40.99
Hamming Accuracy        68.11
Hamming Loss            31.89
Macro F1                42.88
Macro Jaccard           27.86
Macro Precision         50.25
Macro Recall            41.06
Micro F1                46.04
Micro Jaccard           29.91
Micro Precision         50
Micro Recall            42.67
Subset 0/1 Loss         87.76
Subset Accuracy         12.24

DEBUG Writing output data to file "python/tests/res/tmp/results/evaluation_test.csv"...
INFO Predicting for 196 test examples using a model of size 950...
INFO Successfully predicted in <duration>
INFO Evaluation result for test data using a model of size 950:

Example-wise F1         46.17
Example-wise Jaccard    37.64
Example-wise Precision  58.5
Example-wise Recall     41.5
Hamming Accuracy        68.11
Hamming Loss            31.89
Macro F1                43.09
Macro Jaccard           28.03
Macro Precision         50.85
Macro Recall            41.55
Micro F1                46.35
Micro Jaccard           30.17
Micro Precision         50
Micro Recall            43.2
Subset 0/1 Loss         88.27
Subset Accuracy         11.73

DEBUG Writing output data to file "python/tests/res/tmp/results/evaluation_test.csv"...
INFO Predicting for 196 test examples using a model of size 1000...
INFO Successfully predicted in <duration>
INFO Evaluation result for test data using a model of size 1000:

Example-wise F1         45.31
Example-wise Jaccard    37.05
Example-wise Precision  56.97
Example-wise Recall     40.9
Hamming Accuracy        67.35
Hamming Loss            32.65
Macro F1                42.14
Macro Jaccard           27.21
Macro Precision         50.17
Macro Recall            40.96
Micro F1                45.45
Micro Jaccard           29.41
Micro Precision         48.63
Micro Recall            42.67
Subset 0/1 Loss         88.27
Subset Accuracy         11.73

DEBUG Writing output data to file "python/tests/res/tmp/results/evaluation_test.csv"...
DEBUG Writing output data to file "python/tests/res/tmp/models/model.pickle"...
INFO Marginal probability calibration model:

┌──────────────────────┬─────────────────────────┐
│   Label 1 thresholds │   Label 1 probabilities │
├──────────────────────┼─────────────────────────┤
│               0      │                  0      │
│               0.0012 │                  0.2441 │
│               0.026  │                  0.3312 │
│               0.2426 │                  0.4333 │
│               0.404  │                  0.5    │
│               0.7181 │                  0.6094 │
│               0.9848 │                  1      │
└──────────────────────┴─────────────────────────┘
┌──────────────────────┬─────────────────────────┐
│   Label 2 thresholds │   Label 2 probabilities │
├──────────────────────┼─────────────────────────┤
│               0      │                  0      │
│               0.0015 │                  0.2    │
│               0.0019 │                  0.2097 │
│               0.0446 │                  0.2381 │
│               0.0657 │                  0.375  │
│               0.1106 │                  0.3823 │
│               0.3771 │                  0.5    │
│               0.7206 │                  0.7045 │
└──────────────────────┴─────────────────────────┘
┌──────────────────────┬─────────────────────────┐
│   Label 3 thresholds │   Label 3 probabilities │
├──────────────────────┼─────────────────────────┤
│               0      │                  0      │
│               0.0285 │                  0.2    │
│               0.0973 │                  0.5226 │
│               0.9807 │                  0.5655 │
│               0.9983 │                  1      │
└──────────────────────┴─────────────────────────┘
┌──────────────────────┬─────────────────────────┐
│   Label 4 thresholds │   Label 4 probabilities │
├──────────────────────┼─────────────────────────┤
│               0      │                  0      │
│               0.0003 │                  0.0156 │
│               0.0657 │                  0.2667 │
│               0.3108 │                  0.3625 │
│               0.9412 │                  0.7083 │
│               0.9847 │                  1      │
└──────────────────────┴─────────────────────────┘
┌──────────────────────┬─────────────────────────┐
│   Label 5 thresholds │   Label 5 probabilities │
├──────────────────────┼─────────────────────────┤
│               0.0001 │                  0      │
│               0.0018 │                  0.1429 │
│               0.0034 │                  0.2162 │
│               0.044  │                  0.25   │
│               0.0566 │                  0.294  │
│               0.5818 │                  0.3125 │
│               0.9535 │                  1      │
└──────────────────────┴─────────────────────────┘
┌──────────────────────┬─────────────────────────┐
│   Label 6 thresholds │   Label 6 probabilities │
├──────────────────────┼─────────────────────────┤
│               0      │                  0      │
│               0.0008 │                  0.025  │
│               0.0129 │                  0.1667 │
│               0.0244 │                  0.25   │
│               0.2021 │                  0.4664 │
│               0.9622 │                  0.875  │
│               0.9862 │                  1      │
└──────────────────────┴─────────────────────────┘

DEBUG Writing output data to file "python/tests/res/tmp/results/marginal_probability_calibration_model.csv"...
INFO Joint probability calibration model:

┌─────────────────────────────┬────────────────────────────────┐
│   Label vector 1 thresholds │   Label vector 1 probabilities │
├─────────────────────────────┼────────────────────────────────┤
│                      0      │                         0      │
│                      0.0026 │                         0.0625 │
│                      0.0306 │                         0.25   │
│                      0.0517 │                         0.2763 │
│                      0.3458 │                         0.4167 │
│                      0.5272 │                         0.5    │
└─────────────────────────────┴────────────────────────────────┘
┌─────────────────────────────┬────────────────────────────────┐
│   Label vector 2 thresholds │   Label vector 2 probabilities │
├─────────────────────────────┼────────────────────────────────┤
│                      0      │                         0      │
│                      0.0597 │                         0.3333 │
└─────────────────────────────┴────────────────────────────────┘
┌─────────────────────────────┬────────────────────────────────┐
│   Label vector 3 thresholds │   Label vector 3 probabilities │
├─────────────────────────────┼────────────────────────────────┤
│                      0      │                         0.0045 │
│                      0.0024 │                         0.0556 │
│                      0.0094 │                         0.125  │
│                      0.0256 │                         0.2252 │
│                      0.3733 │                         0.3333 │
└─────────────────────────────┴────────────────────────────────┘
┌─────────────────────────────┬────────────────────────────────┐
│   Label vector 4 thresholds │   Label vector 4 probabilities │
├─────────────────────────────┼────────────────────────────────┤
│                      0      │                         0.0111 │
│                      0.0014 │                         0.027  │
│                      0.0608 │                         0.25   │
│                      0.0633 │                         0.5396 │
│                      0.112  │                         0.5702 │
│                      0.3716 │                         1      │
└─────────────────────────────┴────────────────────────────────┘
┌─────────────────────────────┬────────────────────────────────┐
│   Label vector 5 thresholds │   Label vector 5 probabilities │
├─────────────────────────────┼────────────────────────────────┤
│                      0      │                         0      │
│                      0      │                         0.04   │
│                      0.004  │                         0.0833 │
│                      0.0642 │                         0.2542 │
│                      0.1657 │                         0.5    │
│                      0.1746 │                         0.6667 │
│                      0.4224 │                         1      │
└─────────────────────────────┴────────────────────────────────┘
┌─────────────────────────────┬────────────────────────────────┐
│   Label vector 6 thresholds │   Label vector 6 probabilities │
├─────────────────────────────┼────────────────────────────────┤
│                      0      │                         0      │
│                      0.0001 │                         0.0169 │
│                      0.0282 │                         0.1429 │
│                      0.0469 │                         0.25   │
│                      0.086  │                         0.3333 │
│                      0.3682 │                         0.5    │
│                      0.3786 │                         0.6042 │
└─────────────────────────────┴────────────────────────────────┘
┌─────────────────────────────┬────────────────────────────────┐
│   Label vector 7 thresholds │   Label vector 7 probabilities │
├─────────────────────────────┼────────────────────────────────┤
│                      0      │                         0      │
│                      0.0505 │                         0.0357 │
└─────────────────────────────┴────────────────────────────────┘
┌─────────────────────────────┬────────────────────────────────┐
│   Label vector 8 thresholds │   Label vector 8 probabilities │
├─────────────────────────────┼────────────────────────────────┤
│                      0      │                         0.0025 │
│                      0.0041 │                         0.04   │
│                      0.0334 │                         0.2857 │
│                      0.0504 │                         0.3409 │
│                      0.0911 │                         0.3958 │
│                      0.5027 │                         1      │
└─────────────────────────────┴────────────────────────────────┘
┌─────────────────────────────┬────────────────────────────────┐
│   Label vector 9 thresholds │   Label vector 9 probabilities │
├─────────────────────────────┼────────────────────────────────┤
│                      0      │                         0.0012 │
│                      0.0021 │                         0.1429 │
│                      0.0124 │                         0.2121 │
│                      0.0316 │                         0.3214 │
│                      0.0594 │                         0.3333 │
│                      0.0681 │                         0.3381 │
│                      0.1859 │                         0.3472 │
└─────────────────────────────┴────────────────────────────────┘
┌──────────────────────────────┬─────────────────────────────────┐
│   Label vector 10 thresholds │   Label vector 10 probabilities │
├──────────────────────────────┼─────────────────────────────────┤
│                       0      │                          0.0556 │
│                       0.0002 │                          0.1633 │
│                       0.0212 │                          0.2    │
│                       0.0264 │                          0.2105 │
│                       0.0476 │                          0.2833 │
│                       0.0987 │                          0.3333 │
│                       0.1106 │                          0.4444 │
└──────────────────────────────┴─────────────────────────────────┘
┌──────────────────────────────┬─────────────────────────────────┐
│   Label vector 11 thresholds │   Label vector 11 probabilities │
├──────────────────────────────┼─────────────────────────────────┤
│                       0      │                          0      │
│                       0.0122 │                          0.05   │
│                       0.032  │                          0.125  │
│                       0.0472 │                          0.1667 │
│                       0.0564 │                          0.25   │
│                       0.0596 │                          0.2917 │
└──────────────────────────────┴─────────────────────────────────┘
┌──────────────────────────────┬─────────────────────────────────┐
│   Label vector 12 thresholds │   Label vector 12 probabilities │
├──────────────────────────────┼─────────────────────────────────┤
│                       0      │                          0      │
│                       0.0198 │                          0.1538 │
│                       0.0605 │                          0.2336 │
│                       0.2295 │                          0.35   │
│                       0.3173 │                          0.375  │
│                       0.4106 │                          0.4167 │
│                       0.5461 │                          0.5    │
└──────────────────────────────┴─────────────────────────────────┘
┌──────────────────────────────┬─────────────────────────────────┐
│   Label vector 13 thresholds │   Label vector 13 probabilities │
├──────────────────────────────┼─────────────────────────────────┤
│                       0      │                          0      │
│                       0.1266 │                          0.0455 │
└──────────────────────────────┴─────────────────────────────────┘
┌──────────────────────────────┬─────────────────────────────────┐
│   Label vector 14 thresholds │   Label vector 14 probabilities │
├──────────────────────────────┼─────────────────────────────────┤
│                       0      │                          0.0038 │
│                       0.0034 │                          0.2939 │
│                       0.0638 │                          0.6021 │
│                       0.2448 │                          1      │
└──────────────────────────────┴─────────────────────────────────┘
┌──────────────────────────────┬─────────────────────────────────┐
│   Label vector 15 thresholds │   Label vector 15 probabilities │
├──────────────────────────────┼─────────────────────────────────┤
│                       0      │                          0.001  │
│                       0.0044 │                          0.0345 │
│                       0.0198 │                          0.0694 │
│                       0.0561 │                          0.1    │
└──────────────────────────────┴─────────────────────────────────┘
┌──────────────────────────────┬─────────────────────────────────┐
│   Label vector 16 thresholds │   Label vector 16 probabilities │
├──────────────────────────────┼─────────────────────────────────┤
│                       0      │                          0      │
│                       0.0435 │                          0.0714 │
│                       0.1401 │                          0.1667 │
└──────────────────────────────┴─────────────────────────────────┘
┌──────────────────────────────┬─────────────────────────────────┐
│   Label vector 17 thresholds │   Label vector 17 probabilities │
├──────────────────────────────┼─────────────────────────────────┤
│                       0      │                             0   │
│                       0.0411 │                             0.5 │
└──────────────────────────────┴─────────────────────────────────┘
┌──────────────────────────────┬─────────────────────────────────┐
│   Label vector 18 thresholds │   Label vector 18 probabilities │
├──────────────────────────────┼─────────────────────────────────┤
│                            0 │                               0 │
└──────────────────────────────┴─────────────────────────────────┘
┌──────────────────────────────┬─────────────────────────────────┐
│   Label vector 19 thresholds │   Label vector 19 probabilities │
├──────────────────────────────┼─────────────────────────────────┤
│                       0      │                          0      │
│                       0.0208 │                          0.0871 │
│                       0.208  │                          1      │
└──────────────────────────────┴─────────────────────────────────┘
┌──────────────────────────────┬─────────────────────────────────┐
│   Label vector 20 thresholds │   Label vector 20 probabilities │
├──────────────────────────────┼─────────────────────────────────┤
│                       0      │                          0      │
│                       0.0135 │                          0.0313 │
└──────────────────────────────┴─────────────────────────────────┘
┌──────────────────────────────┬─────────────────────────────────┐
│   Label vector 21 thresholds │   Label vector 21 probabilities │
├──────────────────────────────┼─────────────────────────────────┤
│                            0 │                               0 │
└──────────────────────────────┴─────────────────────────────────┘
┌──────────────────────────────┬─────────────────────────────────┐
│   Label vector 22 thresholds │   Label vector 22 probabilities │
├──────────────────────────────┼─────────────────────────────────┤
│                            0 │                               0 │
└──────────────────────────────┴─────────────────────────────────┘
┌──────────────────────────────┬─────────────────────────────────┐
│   Label vector 23 thresholds │   Label vector 23 probabilities │
├──────────────────────────────┼─────────────────────────────────┤
│                       0      │                          0.0145 │
│                       0.0003 │                          0.0204 │
│                       0.0052 │                          0.0357 │
│                       0.1125 │                          0.3333 │
│                       0.2246 │                          1      │
└──────────────────────────────┴─────────────────────────────────┘

DEBUG Writing output data to file "python/tests/res/tmp/results/joint_probability_calibration_model.csv"...
INFO Successfully finished after <duration>
