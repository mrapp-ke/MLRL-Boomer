mlrl-testbed mlrl.boosting --mode read --log-level debug --base-dir python/tests/res/tmp/rerun --input-dir python/tests/res/tmp --save-evaluation true --print-evaluation true --save-evaluation true
Reading meta-data...
Reading input data from file "python/tests/res/tmp/metadata.yml"...
Successfully read meta-data
Checking for version conflicts...
Experimental results have been created with version "<version>" of the package "mlrl-testbed", version "<version>" is currently used
No version conflicts detected
Reading experimental results of 1 experiment...

Reading experimental results of experiment (1 / 1)...
The command "mlrl-testbed mlrl.boosting --log-level debug --base-dir python/tests/res/tmp --data-dir python/tests/res/data --dataset atp7d --result-dir results --problem-type regression --save-evaluation true --predict-for-training-data true --print-evaluation true --save-evaluation true" has been used originally for running this experiment
Using separate training and test sets...
Reading input data from file "python/tests/res/tmp/results/evaluation_training.csv"...
Reading input data from file "python/tests/res/tmp/results/evaluation_test.csv"...
Evaluation result for training data:

Mean Absolute Error (↓)             0.53
Mean Absolute Percentage Error (↓)  0
Mean Squared Error (↓)              0.45
Median Absolute Error (↓)           0.45

Writing output data to file "python/tests/res/tmp/rerun/results/evaluation_training.csv"...
Evaluation result for test data:

Mean Absolute Error (↓)               29.91
Mean Absolute Percentage Error (↓)     0.08
Mean Squared Error (↓)              2826.34
Median Absolute Error (↓)             15.83

Writing output data to file "python/tests/res/tmp/rerun/results/evaluation_test.csv"...
