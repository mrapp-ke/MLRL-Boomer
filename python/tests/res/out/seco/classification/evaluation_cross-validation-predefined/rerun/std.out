mlrl-testbed mlrl.seco --mode read --log-level debug --base-dir python/tests/res/tmp/rerun --input-dir python/tests/res/tmp --save-evaluation true --print-evaluation true --save-evaluation true
Reading meta-data...
Reading input data from file "python/tests/res/tmp/metadata.yml"...
Successfully read meta-data
Checking for version conflicts...
Experimental results have been created with version "<version>" of the package "mlrl-testbed", version "<version>" is currently used
No version conflicts detected
Reading experimental results of 1 experiment...

Reading experimental results of experiment (1 / 1)...
The command "mlrl-testbed mlrl.seco --log-level debug --base-dir python/tests/res/tmp --data-dir python/tests/res/data --dataset emotions-predefined --result-dir results --save-evaluation true --data-split cross-validation --print-evaluation true --save-evaluation true" has been used originally for running this experiment
Performing full 10-fold cross validation...
Fold 1 / 10:
Reading input data from file "python/tests/res/tmp/results/evaluation_test_fold-1.csv"...
Evaluation result for test data (Fold 1):

Example-wise F1 (↑)         54.64
Example-wise Jaccard (↑)    44.89
Example-wise Precision (↑)  59.55
Example-wise Recall (↑)     60.73
Hamming Accuracy (↑)        74.58
Hamming Loss (↓)            25.42
Macro F1 (↑)                51.95
Macro Jaccard (↑)           38.27
Macro Precision (↑)         66.22
Macro Recall (↑)            57.02
Micro F1 (↑)                59.82
Micro Jaccard (↑)           42.68
Micro Precision (↑)         59.29
Micro Recall (↑)            60.36
Subset 0/1 Loss (↓)         84.75
Subset Accuracy (↑)         15.25

Writing output data to file "python/tests/res/tmp/rerun/results/evaluation_test_fold-1.csv"...
Fold 2 / 10:
Reading input data from file "python/tests/res/tmp/results/evaluation_test_fold-2.csv"...
Evaluation result for test data (Fold 2):

Example-wise F1 (↑)         57.75
Example-wise Jaccard (↑)    49.46
Example-wise Precision (↑)  65.82
Example-wise Recall (↑)     60.17
Hamming Accuracy (↑)        74.86
Hamming Loss (↓)            25.14
Macro F1 (↑)                52.03
Macro Jaccard (↑)           38.55
Macro Precision (↑)         70.17
Macro Recall (↑)            55
Micro F1 (↑)                58.6
Micro Jaccard (↑)           41.45
Micro Precision (↑)         60
Micro Recall (↑)            57.27
Subset 0/1 Loss (↓)         74.58
Subset Accuracy (↑)         25.42

Writing output data to file "python/tests/res/tmp/rerun/results/evaluation_test_fold-2.csv"...
Fold 3 / 10:
Reading input data from file "python/tests/res/tmp/results/evaluation_test_fold-3.csv"...
Evaluation result for test data (Fold 3):

Example-wise F1 (↑)         55.17
Example-wise Jaccard (↑)    45.83
Example-wise Precision (↑)  71.94
Example-wise Recall (↑)     56.39
Hamming Accuracy (↑)        76.39
Hamming Loss (↓)            23.61
Macro F1 (↑)                52.17
Macro Jaccard (↑)           38.47
Macro Precision (↑)         74.24
Macro Recall (↑)            51.26
Micro F1 (↑)                58.54
Micro Jaccard (↑)           41.38
Micro Precision (↑)         65.22
Micro Recall (↑)            53.1
Subset 0/1 Loss (↓)         80
Subset Accuracy (↑)         20

Writing output data to file "python/tests/res/tmp/rerun/results/evaluation_test_fold-3.csv"...
Fold 4 / 10:
Reading input data from file "python/tests/res/tmp/results/evaluation_test_fold-4.csv"...
Evaluation result for test data (Fold 4):

Example-wise F1 (↑)         56.27
Example-wise Jaccard (↑)    47.88
Example-wise Precision (↑)  65.82
Example-wise Recall (↑)     58.76
Hamming Accuracy (↑)        75.71
Hamming Loss (↓)            24.29
Macro F1 (↑)                52.64
Macro Jaccard (↑)           38.98
Macro Precision (↑)         67.91
Macro Recall (↑)            55.26
Micro F1 (↑)                59.81
Micro Jaccard (↑)           42.67
Micro Precision (↑)         61.54
Micro Recall (↑)            58.18
Subset 0/1 Loss (↓)         76.27
Subset Accuracy (↑)         23.73

Writing output data to file "python/tests/res/tmp/rerun/results/evaluation_test_fold-4.csv"...
Fold 5 / 10:
Reading input data from file "python/tests/res/tmp/results/evaluation_test_fold-5.csv"...
Evaluation result for test data (Fold 5):

Example-wise F1 (↑)         57.55
Example-wise Jaccard (↑)    48.45
Example-wise Precision (↑)  66.53
Example-wise Recall (↑)     64.69
Hamming Accuracy (↑)        74.29
Hamming Loss (↓)            25.71
Macro F1 (↑)                53.1
Macro Jaccard (↑)           39.62
Macro Precision (↑)         65.96
Macro Recall (↑)            60.9
Micro F1 (↑)                60.26
Micro Jaccard (↑)           43.12
Micro Precision (↑)         57.5
Micro Recall (↑)            63.3
Subset 0/1 Loss (↓)         76.27
Subset Accuracy (↑)         23.73

Writing output data to file "python/tests/res/tmp/rerun/results/evaluation_test_fold-5.csv"...
Fold 6 / 10:
Reading input data from file "python/tests/res/tmp/results/evaluation_test_fold-6.csv"...
Evaluation result for test data (Fold 6):

Example-wise F1 (↑)         54.24
Example-wise Jaccard (↑)    46.19
Example-wise Precision (↑)  65.25
Example-wise Recall (↑)     57.91
Hamming Accuracy (↑)        75.42
Hamming Loss (↓)            24.58
Macro F1 (↑)                52.84
Macro Jaccard (↑)           39.19
Macro Precision (↑)         73.32
Macro Recall (↑)            55.34
Micro F1 (↑)                58.77
Micro Jaccard (↑)           41.61
Micro Precision (↑)         61.39
Micro Recall (↑)            56.36
Subset 0/1 Loss (↓)         76.27
Subset Accuracy (↑)         23.73

Writing output data to file "python/tests/res/tmp/rerun/results/evaluation_test_fold-6.csv"...
Fold 7 / 10:
Reading input data from file "python/tests/res/tmp/results/evaluation_test_fold-7.csv"...
Evaluation result for test data (Fold 7):

Example-wise F1 (↑)         48.62
Example-wise Jaccard (↑)    39.97
Example-wise Precision (↑)  65.67
Example-wise Recall (↑)     50.83
Hamming Accuracy (↑)        72.5
Hamming Loss (↓)            27.5
Macro F1 (↑)                47.89
Macro Jaccard (↑)           33.9
Macro Precision (↑)         65.25
Macro Recall (↑)            49.03
Micro F1 (↑)                53.52
Micro Jaccard (↑)           36.54
Micro Precision (↑)         57
Micro Recall (↑)            50.44
Subset 0/1 Loss (↓)         83.33
Subset Accuracy (↑)         16.67

Writing output data to file "python/tests/res/tmp/rerun/results/evaluation_test_fold-7.csv"...
Fold 8 / 10:
Reading input data from file "python/tests/res/tmp/results/evaluation_test_fold-8.csv"...
Evaluation result for test data (Fold 8):

Example-wise F1 (↑)         55.99
Example-wise Jaccard (↑)    47.46
Example-wise Precision (↑)  66.81
Example-wise Recall (↑)     60.17
Hamming Accuracy (↑)        76.55
Hamming Loss (↓)            23.45
Macro F1 (↑)                54.6
Macro Jaccard (↑)           42.09
Macro Precision (↑)         69.86
Macro Recall (↑)            59.53
Micro F1 (↑)                61.4
Micro Jaccard (↑)           44.3
Micro Precision (↑)         62.26
Micro Recall (↑)            60.55
Subset 0/1 Loss (↓)         77.97
Subset Accuracy (↑)         22.03

Writing output data to file "python/tests/res/tmp/rerun/results/evaluation_test_fold-8.csv"...
Fold 9 / 10:
Reading input data from file "python/tests/res/tmp/results/evaluation_test_fold-9.csv"...
Evaluation result for test data (Fold 9):

Example-wise F1 (↑)         54.36
Example-wise Jaccard (↑)    46.44
Example-wise Precision (↑)  65.08
Example-wise Recall (↑)     60.73
Hamming Accuracy (↑)        74.86
Hamming Loss (↓)            25.14
Macro F1 (↑)                53.53
Macro Jaccard (↑)           39.58
Macro Precision (↑)         66.04
Macro Recall (↑)            59.83
Micro F1 (↑)                60.79
Micro Jaccard (↑)           43.67
Micro Precision (↑)         58.97
Micro Recall (↑)            62.73
Subset 0/1 Loss (↓)         76.27
Subset Accuracy (↑)         23.73

Writing output data to file "python/tests/res/tmp/rerun/results/evaluation_test_fold-9.csv"...
Fold 10 / 10:
Reading input data from file "python/tests/res/tmp/results/evaluation_test_fold-10.csv"...
Evaluation result for test data (Fold 10):

Example-wise F1 (↑)         52.75
Example-wise Jaccard (↑)    43.47
Example-wise Precision (↑)  66.11
Example-wise Recall (↑)     61.67
Hamming Accuracy (↑)        73.61
Hamming Loss (↓)            26.39
Macro F1 (↑)                52.12
Macro Jaccard (↑)           38.11
Macro Precision (↑)         65.83
Macro Recall (↑)            58.12
Micro F1 (↑)                58.52
Micro Jaccard (↑)           41.36
Micro Precision (↑)         57.76
Micro Recall (↑)            59.29
Subset 0/1 Loss (↓)         85
Subset Accuracy (↑)         15

Writing output data to file "python/tests/res/tmp/rerun/results/evaluation_test_fold-10.csv"...
Evaluation result for test data (Average across 10 folds):

Example-wise F1 (↑)         54.73  ±2.51
Example-wise Jaccard (↑)    46     ±2.61
Example-wise Precision (↑)  65.86  ±2.82
Example-wise Recall (↑)     59.21  ±3.50
Hamming Accuracy (↑)        74.88  ±1.17
Hamming Loss (↓)            25.12  ±1.17
Macro F1 (↑)                52.29  ±1.66
Macro Jaccard (↑)           38.68  ±1.93
Macro Precision (↑)         68.48  ±3.11
Macro Recall (↑)            56.13  ±3.60
Micro F1 (↑)                59     ±2.06
Micro Jaccard (↑)           41.88  ±2.03
Micro Precision (↑)         60.09  ±2.42
Micro Recall (↑)            58.16  ±3.85
Subset 0/1 Loss (↓)         79.07  ±3.73
Subset Accuracy (↑)         20.93  ±3.73

Writing output data to file "python/tests/res/tmp/rerun/results/evaluation_test.csv"...
