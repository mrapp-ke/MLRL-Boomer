mlrl-testbed mlrl.seco --mode read --log-level debug --base-dir python/tests/res/tmp/rerun --input-dir python/tests/res/tmp --save-evaluation true --print-evaluation true --save-evaluation true
Reading meta-data...
Reading input data from file "python/tests/res/tmp/metadata.yml"...
Successfully read meta-data
Checking for version conflicts...
Experimental results have been created with version "<version>" of the package "mlrl-testbed", version "<version>" is currently used
No version conflicts detected
Reading experimental results of 1 experiment...

Reading experimental results of experiment (1 / 1)...
The command "mlrl-testbed mlrl.seco --log-level debug --base-dir python/tests/res/tmp --data-dir python/tests/res/data --dataset emotions --result-dir results --save-evaluation true --data-split cross-validation{first_fold=1,last_fold=1} --print-evaluation true --save-evaluation true" has been used originally for running this experiment
Performing fold 1 of 10-fold cross validation...
Fold 1 / 10:
Reading input data from file "python/tests/res/tmp/results/evaluation_test_fold-1.csv"...
Evaluation result for test data (Fold 1):

Example-wise F1 (↑)         56.63
Example-wise Jaccard (↑)    46.67
Example-wise Precision (↑)  68.33
Example-wise Recall (↑)     60.56
Hamming Accuracy (↑)        74.72
Hamming Loss (↓)            25.28
Macro F1 (↑)                54.04
Macro Jaccard (↑)           40.46
Macro Precision (↑)         74.52
Macro Recall (↑)            57.15
Micro F1 (↑)                60.61
Micro Jaccard (↑)           43.48
Micro Precision (↑)         61.4
Micro Recall (↑)            59.83
Subset 0/1 Loss (↓)         81.67
Subset Accuracy (↑)         18.33

Writing output data to file "python/tests/res/tmp/rerun/results/evaluation_test_fold-1.csv"...
