mlrl-testbed mlrl.seco --log-level debug --base-dir python/tests/res/tmp --data-dir python/tests/res/data --dataset emotions-nominal --result-dir results --save-evaluation true --feature-format sparse
Starting experiment using the classification algorithm "SeCoClassifier"...
Writing output data to file "python/tests/res/tmp/metadata.yml"...
Using separate training and test sets...
Reading input data from file "python/tests/res/data/emotions-nominal.arff"...
Parsing meta-data from file "python/tests/res/data/emotions-nominal.xml"...
Fitting model to 397 training examples...
A sparse matrix with sparse value 0.0 is used to store the feature values of the training examples
A dense matrix is used to store the labels of the training examples
Successfully fit model in <duration>
Predicting for 196 test examples...
A sparse matrix with sparse value 0.0 is used to store the feature values of the query examples
A dense matrix is used to store the predicted labels
Successfully predicted in <duration>
Evaluation result for test data:

Example-wise F1 (↑)         55.5
Example-wise Jaccard (↑)    45.33
Example-wise Precision (↑)  60.51
Example-wise Recall (↑)     60.29
Hamming Accuracy (↑)        72.96
Hamming Loss (↓)            27.04
Macro F1 (↑)                53.08
Macro Jaccard (↑)           38.79
Macro Precision (↑)         51.13
Macro Recall (↑)            57.98
Micro F1 (↑)                58.81
Micro Jaccard (↑)           41.65
Micro Precision (↑)         57.18
Micro Recall (↑)            60.53
Subset 0/1 Loss (↓)         83.67
Subset Accuracy (↑)         16.33

Writing output data to file "python/tests/res/tmp/results/evaluation_test.csv"...
Successfully finished experiment after <duration>
