mlrl-testbed mlrl.seco --log-level debug --base-dir python/tests/res/tmp --data-dir python/tests/res/data --dataset langlog --result-dir results --save-evaluation true --feature-format sparse
Starting experiment using the classification algorithm "SeCoClassifier"...
Writing output data to file "python/tests/res/tmp/metadata.yml"...
Using separate training and test sets...
Reading input data from file "python/tests/res/data/langlog.arff"...
Parsing meta-data from file "python/tests/res/data/langlog.xml"...
Fitting model to 978 training examples...
A sparse matrix with sparse value 0.0 is used to store the feature values of the training examples
A sparse matrix is used to store the labels of the training examples
Successfully fit model in <duration>
Predicting for 482 test examples...
A sparse matrix with sparse value 0.0 is used to store the feature values of the query examples
A sparse matrix is used to store the predicted labels
Successfully predicted in <duration>
Evaluation result for test data:

Example-wise F1 (↑)         27.41
Example-wise Jaccard (↑)    26.09
Example-wise Precision (↑)  80.78
Example-wise Recall (↑)     28.15
Hamming Accuracy (↑)        98.31
Hamming Loss (↓)             1.69
Macro F1 (↑)                12.03
Macro Jaccard (↑)           10.45
Macro Precision (↑)         84.63
Macro Recall (↑)            11.37
Micro F1 (↑)                20.52
Micro Jaccard (↑)           11.43
Micro Precision (↑)         37.98
Micro Recall (↑)            14.06
Subset 0/1 Loss (↓)         77.39
Subset Accuracy (↑)         22.61

Writing output data to file "python/tests/res/tmp/results/evaluation_test.csv"...
Successfully finished experiment after <duration>
