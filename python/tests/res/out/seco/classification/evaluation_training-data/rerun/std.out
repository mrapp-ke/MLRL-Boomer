mlrl-testbed mlrl.seco --mode read --log-level debug --base-dir python/tests/res/tmp/rerun --input-dir python/tests/res/tmp --save-evaluation true --print-evaluation true --save-evaluation true
Reading meta-data...
Reading input data from file "python/tests/res/tmp/metadata.yml"...
Successfully read meta-data
Checking for version conflicts...
Experimental results have been created with version "<version>" of the package "mlrl-testbed", version "<version>" is currently used
No version conflicts detected
Reading experimental results of 1 experiment...

Reading experimental results of experiment (1 / 1)...
The command "mlrl-testbed mlrl.seco --log-level debug --base-dir python/tests/res/tmp --data-dir python/tests/res/data --dataset emotions --result-dir results --save-evaluation true --predict-for-training-data true --print-evaluation true --save-evaluation true" has been used originally for running this experiment
Using separate training and test sets...
Reading input data from file "python/tests/res/tmp/results/evaluation_training.csv"...
Reading input data from file "python/tests/res/tmp/results/evaluation_test.csv"...
Evaluation result for training data:

Example-wise F1         65.36
Example-wise Jaccard    56.87
Example-wise Precision  77.02
Example-wise Recall     68.93
Hamming Accuracy        81.95
Hamming Loss            18.05
Macro F1                62.16
Macro Jaccard           50.04
Macro Precision         77.44
Macro Recall            66.99
Micro F1                70.14
Micro Jaccard           54.01
Micro Precision         71.43
Micro Recall            68.89
Subset 0/1 Loss         69.02
Subset Accuracy         30.98

Writing output data to file "python/tests/res/tmp/rerun/results/evaluation_training.csv"...
Evaluation result for test data:

Example-wise F1         53.72
Example-wise Jaccard    44.55
Example-wise Precision  63.06
Example-wise Recall     59.18
Hamming Accuracy        72.96
Hamming Loss            27.04
Macro F1                50.95
Macro Jaccard           36.98
Macro Precision         64.57
Macro Recall            56.59
Micro F1                58.16
Micro Jaccard           41
Micro Precision         57.4
Micro Recall            58.93
Subset 0/1 Loss         81.63
Subset Accuracy         18.37

Writing output data to file "python/tests/res/tmp/rerun/results/evaluation_test.csv"...
