mlrl-testbed mlrl.seco --mode read --log-level debug --base-dir python/tests/res/tmp/rerun --input-dir python/tests/res/tmp --save-evaluation true --print-evaluation true --save-evaluation true
Reading meta-data...
Reading input data from file "python/tests/res/tmp/metadata.yml"...
Successfully read meta-data
Checking for version conflicts...
Experimental results have been created with version "<version>" of the package "mlrl-testbed", version "<version>" is currently used
No version conflicts detected
Reading experimental results of 1 experiment...

Reading experimental results of experiment (1 / 1)...
The command "mlrl-testbed mlrl.seco --log-level debug --base-dir python/tests/res/tmp --data-dir python/tests/res/data --dataset emotions --result-dir results --save-evaluation true --incremental-evaluation true{step_size=50} --print-evaluation true --save-evaluation true" has been used originally for running this experiment
Using separate training and test sets...
Reading input data from file "python/tests/res/tmp/results/evaluation_test.csv"...
Evaluation result for test data using a model of size 50:

Example-wise F1         52.09
Example-wise Jaccard    43.17
Example-wise Precision  65.23
Example-wise Recall     56.46
Hamming Accuracy        73.3
Hamming Loss            26.7
Macro F1                49.73
Macro Jaccard           35.98
Macro Precision         65.08
Macro Recall            53.78
Micro F1                57.34
Micro Jaccard           40.19
Micro Precision         58.45
Micro Recall            56.27
Subset 0/1 Loss         81.12
Subset Accuracy         18.88

Writing output data to file "python/tests/res/tmp/rerun/results/evaluation_test.csv"...
Evaluation result for test data using a model of size 62:

Example-wise F1         53.72
Example-wise Jaccard    44.55
Example-wise Precision  63.06
Example-wise Recall     59.18
Hamming Accuracy        72.96
Hamming Loss            27.04
Macro F1                50.95
Macro Jaccard           36.98
Macro Precision         64.57
Macro Recall            56.59
Micro F1                58.16
Micro Jaccard           41
Micro Precision         57.4
Micro Recall            58.93
Subset 0/1 Loss         81.63
Subset Accuracy         18.37

Writing output data to file "python/tests/res/tmp/rerun/results/evaluation_test.csv"...
