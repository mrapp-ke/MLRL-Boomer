mlrl-testbed mlrl.seco --log-level DEBUG --data-dir python/tests/res/data --dataset emotions --output-dir python/tests/res/tmp/results --incremental-evaluation true{step_size=50} --print-evaluation true --store-evaluation true
INFO Starting experiment using the classification algorithm "seco"...
INFO Using separate training and test sets...
DEBUG Loading data set from file "python/tests/res/data/emotions.arff"...
DEBUG Parsing meta-data from file "python/tests/res/data/emotions.xml"...
INFO Fitting model to 397 training examples...
DEBUG A dense matrix is used to store the feature values of the training examples
DEBUG A dense matrix is used to store the labels of the training examples
INFO Successfully fit model in <duration>
DEBUG A dense matrix is used to store the feature values of the query examples
DEBUG A dense matrix is used to store the predicted labels
INFO Predicting for 196 test examples using a model of size 50...
INFO Successfully predicted in <duration>
INFO Evaluation result for test data using a model of size 50:

Example-wise F1         52.09
Example-wise Jaccard    43.17
Example-wise Precision  65.23
Example-wise Recall     56.46
Hamming Accuracy        73.3
Hamming Loss            26.7
Macro F1                49.73
Macro Jaccard           35.98
Macro Precision         65.08
Macro Recall            53.78
Micro F1                57.34
Micro Jaccard           40.19
Micro Precision         58.45
Micro Recall            56.27
Subset 0/1 Loss         81.12
Subset Accuracy         18.88

DEBUG Writing output data to file "python/tests/res/tmp/results/evaluation_test_overall.csv"...
INFO Predicting for 196 test examples using a model of size 62...
INFO Successfully predicted in <duration>
INFO Evaluation result for test data using a model of size 62:

Example-wise F1         53.72
Example-wise Jaccard    44.55
Example-wise Precision  63.06
Example-wise Recall     59.18
Hamming Accuracy        72.96
Hamming Loss            27.04
Macro F1                50.95
Macro Jaccard           36.98
Macro Precision         64.57
Macro Recall            56.59
Micro F1                58.16
Micro Jaccard           41
Micro Precision         57.4
Micro Recall            58.93
Subset 0/1 Loss         81.63
Subset Accuracy         18.37

DEBUG Writing output data to file "python/tests/res/tmp/results/evaluation_test_overall.csv"...
INFO Successfully finished after <duration>
