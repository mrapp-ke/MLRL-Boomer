mlrl-testbed mlrl.testbed_sklearn --log-level debug --base-dir python/tests/res/tmp --data-dir python/tests/res/data --dataset emotions --result-dir results --save-evaluation true --data-split none --print-evaluation true --save-evaluation true --n-estimators 1 --estimator RandomForestClassifier
Checking if output files do already exist...
Starting experiment using the classification algorithm "RandomForestClassifier"...
DEBUG: Writing output data to file "python/tests/res/tmp/metadata.yml"...
WARNING: Not using separate training and test sets. The model will be evaluated on the training data...
DEBUG: Reading input data from file "python/tests/res/data/emotions.arff"...
DEBUG: Parsing meta-data from file "python/tests/res/data/emotions.xml"...
Fitting model to 593 training examples...
Successfully fit model in <duration>
Predicting for 593 training examples...
Successfully predicted in <duration>
Evaluation result for training data:

Example-wise F1 (↑)         81.05
Example-wise Jaccard (↑)    78.04
Example-wise Precision (↑)  82.01
Example-wise Recall (↑)     82.15
Hamming Accuracy (↑)        89.04
Hamming Loss (↓)            10.96
Macro F1 (↑)                82.36
Macro Jaccard (↑)           70.11
Macro Precision (↑)         82.25
Macro Recall (↑)            82.55
Micro F1 (↑)                82.45
Micro Jaccard (↑)           70.14
Micro Precision (↑)         82.23
Micro Recall (↑)            82.67
Subset 0/1 Loss (↓)         30.35
Subset Accuracy (↑)         69.65

DEBUG: Writing output data to file "python/tests/res/tmp/results/evaluation_training.csv"...
Successfully finished experiment after <duration>
